[
  {
    "objectID": "WGAN.html",
    "href": "WGAN.html",
    "title": "Wasserstein Generative Adversarial Network",
    "section": "",
    "text": "The Wasserstein generative adversarial network (WGAN) (Arjovsky, Chintala, and Bottou 2017) is a recently proposed state-of-the-art generative model that leverages ideas from optimal transport to address key limitations of the traditional generative adversarial network (GAN) (Goodfellow et al. 2014).\nTo provide a comprehensive introduction to WGAN, we begin by clarifying the problem of generative modeling. Among various approaches, we focus specifically on GANs, outlining their main ideas and performing a straightforward theoretical analysis. Motivated by the challenges encountered in the training of GANs, WGANs are naturally introduced, highlighting how ideas from optimal transport improve the performance and stability of machine learning models."
  },
  {
    "objectID": "WGAN.html#general-overview",
    "href": "WGAN.html#general-overview",
    "title": "Wasserstein Generative Adversarial Network",
    "section": "General Overview",
    "text": "General Overview\nIn recent years, it has been a hot topic to train machine learning models that exhibit human capabilities, one of which is creativity — the ability to create novel objects within a given category after observing a set of examples. Just like a human child, who can draw numerous distinct cats after seeing just a few real-life cats, one example of generative modeling is to train a machine learning model based on a set of cat images, which can produce an unlimited variety of new cat images that do not resemble those in the training set.\nIn brief, the problem of generative modeling has the following requirements:\n\nThe training set consists of a finite number of samples.\nThe generated outputs belong to the same category as the training samples.\nThe model is capable of producing an infinite variety of outputs.\n\nGenerative models have numerous connections and applications in various fields, e.g., synthetic data generation (Eigenschink et al. 2023), image generation (Oussidi and Elhassouny 2018), game theory (Cao, Guo, and Laurière 2020) and reinforcement learning (Franceschelli and Musolesi 2024), etc. We refer interested readers to (Harshvardhan et al. 2020) for a comprehensive survey on the analysis and applications of generative models."
  },
  {
    "objectID": "WGAN.html#problem-formulation",
    "href": "WGAN.html#problem-formulation",
    "title": "Wasserstein Generative Adversarial Network",
    "section": "Problem Formulation",
    "text": "Problem Formulation\nLet \\(\\mathcal{X}\\subset \\mathbb{R}^D\\) denote the sample space where training samples take values. The key assumption of generative modeling is the existence of an unknown probability distribution \\(\\mathbb{P}_r\\) on \\(\\mathcal{X}\\), from which the training samples are drawn. Therefore, generative modeling typically consists of two parts:\n\nApproximation: Approximate the distribution \\(\\mathbb{P}_r\\) with a parameterized model \\(\\mathbb{P}_\\theta\\in\\mathscr{P}(\\mathcal{X})\\), where \\(\\theta\\) represents the parameters, based on the finite number of training samples from \\(\\mathbb{P}_r\\).\nSampling: Generate samples from the approximated distribution \\(\\mathbb{P}_\\theta\\).\n\nIn the example of generating cat images, the approximation step concludes the features of cats, e.g., with a tail and four legs, while the sampling step creates new cat images based on the features learnt in the previous step. We remark that, the features learnt in the approximation step depend heavily on the quality of the training samples. If all the training samples are only showing black cats, then the color feature learnt by the model might be “all cats are black”, which is not necessarily the ground truth."
  },
  {
    "objectID": "WGAN.html#geometric-structure",
    "href": "WGAN.html#geometric-structure",
    "title": "Wasserstein Generative Adversarial Network",
    "section": "Geometric Structure",
    "text": "Geometric Structure\nBefore diving deeper into state-of-the-art methods of generative modeling, it is crucial to understand why classical density estimation methods in Statistics are not performing well. One of the reasons lies in the geometric structure of the problem that the distribution \\(\\mathbb{P}_r\\), in most cases, is supported only on a low-dimensional manifold within \\(\\mathbb{R}^D\\).\nConsider the task of image generation, where each image consists of approximately \\(10^6\\) pixels with three color channels, i.e., \\(D \\approx 3\\times 10^6\\). While each one of the images can be viewed as a single point in \\(\\mathbb{R}^D\\), the true distribution \\(\\mathbb{P}_r\\) is typically concentrated on a manifold with an intrinsic dimension \\(d\\), where \\(d\\leq 50\\) for most image datasets (Pope et al. 2021). This significant gap between the ambient dimension \\(D\\) and the intrinsic dimension \\(d\\) arises from implicit constraints that define the structure of \\(\\mathbb{P}_r\\). For instance, human face images require symmetry and the nose and ears have to adhere to specific shape characteristics.\nUnder this specific structure, perturbation-based sampling methods, which refer to the generation of a randomly perturbed version of one of the training samples, no longer work. As a simple example illustrating such failure, consider \\(\\mathbb{P}_r\\) as a uniform distribution on a unit circle \\(C^1\\subset\\mathbb{R}^2\\). Adding Gaussian noises to a point \\((x,y)\\in C^1\\) almost surely yields a point outside the manifold \\(C^1\\). In other words, general perturbations would destroy the manifold structure, if not carefully designed.\nSimilarly, classical density estimation methods face at least two major challenges:\n\nThe density approximation on the manifold. The density of \\(\\mathbb{P}_r\\), if exists on the manifold, is almost everywhere zero under the Lebesgue measure on \\(\\mathbb{R}^D\\).\nThe density-based sampling scheme. Sampling from a distribution on a high-dimensional space with a known density suffers from the curse of dimensionality.\n\nThose challenges motivate the development of state-of-the-art generative modeling approaches based on different ideas, as introduced in the following section."
  },
  {
    "objectID": "WGAN.html#sota-approaches",
    "href": "WGAN.html#sota-approaches",
    "title": "Wasserstein Generative Adversarial Network",
    "section": "SOTA Approaches",
    "text": "SOTA Approaches\nPopular methods of generative modeling can be roughly categorized as:\n\nVariational Autoencoders (VAEs): VAEs are likelihood-based generative models that train an encoder to map samples to a latent space and a decoder to reconstruct samples from latent vectors.\nGenerative Adversarial Networks (GANs): GANs involve a generator and a discriminator network trained in an adversarial way, where the discriminator learns to distinguish between real and generated data, while the generator aims to create samples indistinguishable from real data.\nDiffusion models: Diffusion models progressively corrupt samples by adding random noise and reverses this process, reconstructing new samples from pure random noise.\n\nWhile all approaches share the same objective, their methodologies differ significantly. In the following discussion, we briefly introduce GANs to prepare the readers for the discussion on WGANs."
  },
  {
    "objectID": "WGAN.html#main-idea",
    "href": "WGAN.html#main-idea",
    "title": "Wasserstein Generative Adversarial Network",
    "section": "Main Idea",
    "text": "Main Idea\nAs mentioned above, a generative model shall have the “power of infinity”, i.e., the ability to produce an infinite variety of outputs. However, when it comes to numerical implementations of most algorithms, we are always trying to discretize continuous objects. For example, when numerical integration is performed, the integration domain is discretized into a large (but finite) number of small areas. Attaining infinity seems impossible at the first glance, but modern computers do attain infinity in one specific task — generating random samples from a given distribution. We draw distinct samples from a multivariate standard Gaussian \\(N(0,I)\\) each time the random number generator is called, which is actually the source of the “power of infinity”. Inspired by such observations, generative models shall learn how to map random samples from a known distribution, e.g., \\(N(0,I)\\), to outputs that follow \\(\\mathbb{P}_r\\), i.e., the models should be delivering randomness, rather than creating new randomness.\nMathematically speaking, we call \\(\\mathcal{Z}\\subset \\mathbb{R}^l\\) the latent space, where the latent random variable \\(Z\\) takes values. The random variable \\(Z\\) follows a given probability distribution \\(\\mathbb{P}_Z\\), which is often taken as a multivariate Gaussian. A GAN aims to learn a function parameterized by \\(\\theta\\): \\[\nG_\\theta:\\mathcal{Z}\\to\\mathcal{X},\n\\] such that the law of \\(G_\\theta(Z)\\) is approximately \\(\\mathbb{P}_r\\). In practice, \\(G_\\theta\\) is typically taken as a neural network, while \\(\\theta\\) denotes the collection of all the network paramaters. For the purpose of notation, we denote \\(\\mathbb{P}_\\theta\\) as the law of \\(G_\\theta(Z)\\), i.e., \\(\\mathbb{P}_\\theta = (G_\\theta)_\\#\\mathbb{P}_Z\\), so that the problem turns into: \\[\n\\inf_\\theta d(\\mathbb{P}_\\theta,\\mathbb{P}_r),\n\\] where \\(d\\) is some information divergence that measures the difference between two probability distributions. Such a formulation naturally poses two questions:\n\nHow to supervise the model with the finite number of training samples from \\(\\mathbb{P}_r\\)?\nHow to select the information divergence \\(d\\)?\n\nThe wisdom of GANs lies in using another neural network to approximate \\(d\\) without specifying it explicitly. The network that approximates \\(d\\) is parameterized by \\(w\\): \\[\nD_w:\\mathcal{X}\\to[0,1].\n\\]\nThe fundamental framework of GANs consists of a generator \\(G_\\theta\\) and a discriminator \\(D_w\\). The generator receives inputs as samples \\(z\\) from the known distribution \\(\\mathbb{P}_Z\\) and outputs the generated samples \\(G_\\theta(z)\\in\\mathcal{X}\\). The discriminator receives inputs as elements in \\(\\mathcal{X}\\) (could be samples in the training set or outputs of the generator \\(G_\\theta(z)\\)), and assigns a score as the probability that the input received is from the true distribution \\(\\mathbb{P}_r\\). In principle, the discriminator hopes to distinguish the training samples from \\(\\mathbb{P}_r\\) and the fake samples from \\(\\mathbb{P}_\\theta\\) that are produced by the generator, while the generator hopes to fool the discriminator on the top of that. Since the GAN architecture creates a competition between the generator and the discriminator, ideally, both networks perform well enough in fulfilling their respective tasks after training. The trained generator is exactly the generative model we have been referring to, while the auxiliary discriminator is simply disregarded.\nWith the GAN architecture in mind, it suffices to propose loss functions for both networks, as the only missing components. The constructions of loss functions are rather intuitive: if the input of the discriminator comes from \\(\\mathbb{P}_r\\), its output shall be close to one; if the input of the discriminator comes from \\(\\mathbb{P}_\\theta\\), its output shall be close to zero. With the logarithms introduced, the discriminator maximizes \\(\\mathbb{E}_{X\\sim\\mathbb{P}_r}\\log D_\\omega(X) + \\mathbb{E}_{Z\\sim\\mathbb{P}_Z}\\log (1-D_\\omega(G_\\theta(Z)))\\) w.r.t. \\(w\\). When the discriminator reaches its optimum, the generator aims to minimize the same loss in order to fool the discriminator, resulting in the optimization problem: \\[\n\\inf_\\theta\\sup_\\omega \\mathbb{E}_{X\\sim\\mathbb{P}_r}\\log D_\\omega(X) + \\mathbb{E}_{Z\\sim\\mathbb{P}_Z}\\log (1-D_\\omega(G_\\theta(Z))).\n\\]\nWe leave the following remarks on the training of GANs:\n\nThe generator and the discriminator share exactly the same loss function, but are optimizing it in opposite directions. In this sense, GAN has essential difference from the well-known actor-critic algorithm in reinforcement learning, where two networks have their respective loss functions to optimize.\nThe expectations in the loss functions are approximated by Monte Carlo. For numerical implementations, one only needs to compute the loss function, call backpropagation for gradient computations (w.r.t. \\(w\\) and \\(\\theta\\)), and conduct gradient descent/ascent for the parameters of the generator/discriminator network.\nDue to the inf-sup structure of the problem, one typically trains the discriminator for several epochs before training the generator for a single epoch. GANs work in the way that the training samples supervise the discriminator, and the discriminator supervises the generator."
  },
  {
    "objectID": "WGAN.html#theoretical-analysis",
    "href": "WGAN.html#theoretical-analysis",
    "title": "Wasserstein Generative Adversarial Network",
    "section": "Theoretical Analysis",
    "text": "Theoretical Analysis\nWe demonstrate a simple theoretical analysis for the GAN optimization problem (Goodfellow et al. 2014). Due to technical difficulties modeling the parameter optimization procedure within neural networks, we omit the dependence on the parameters \\(\\theta\\) and \\(w\\), and rewrite the optimization problem in terms of the generator \\(G\\) and the discriminator \\(D\\). For simplicity, we adopt a change of variable \\(Y := G(Z)\\) to absorb all dependencies on the generator \\(G\\). Since \\(Y\\) is the output of the generator, it follows the distribution \\(\\mathbb{P}_\\theta\\). The inner layer optimization of the inf-sup problem turns out to be explicitly solvable: \\[\n\\sup_D f(D):=\\mathbb{E}_{X\\sim\\mathbb{P}_r}\\log D(X) + \\mathbb{E}_{Y\\sim\\mathbb{P}_\\theta}\\log (1-D(Y)).\n\\] Compute the first variation of \\(f\\) in \\(D\\) w.r.t. the perturbation \\(\\psi\\): \\[\n\\delta f(D)(\\psi) := \\lim_{\\varepsilon\\to 0}\\frac{f(D + \\varepsilon \\psi) - f(D)}{\\varepsilon}\n= \\mathbb{E}_{X\\sim\\mathbb{P}_r}\\frac{\\psi(X)}{D(X)} - \\mathbb{E}_{Y\\sim\\mathbb{P}_\\theta}\\frac{\\psi(Y)}{1-D(Y)}.\n\\] Assume \\(\\mathbb{P}_r\\) and \\(\\mathbb{P}_\\theta\\) have respective densities \\(p_r\\) and \\(p_\\theta\\) w.r.t. the Lebesgue measure. The optimality criterion \\(\\delta f(D^*)(\\psi) = 0\\), \\(\\forall \\psi\\) implies that \\[\nD^* = \\frac{p_r}{p_r + p_\\theta}.\n\\] Plugging back into the objective function yields \\[\nf(D^*) = \\int \\left[p_r(x)\\log\\frac{p_r(x)}{\\frac{p_r(x) + p_\\theta(x)}{2}} + p_\\theta(x)\\log\\frac{p_\\theta(x)}{\\frac{p_r(x) + p_\\theta(x)}{2}}\\right]\\,dx - 2\\log 2.\n\\] This quantity can be identified with the Jensen-Shannon divergence: \\[\nf(D^*) = D_{\\text{KL}} \\left(\\mathbb{P}_r||\\frac{\\mathbb{P}_r + \\mathbb{P}_\\theta}{2}\\right) + D_{\\text{KL}} \\left(\\mathbb{P}_\\theta||\\frac{\\mathbb{P}_r + \\mathbb{P}_\\theta}{2}\\right) - 2\\log 2=: 2\\text{JS}(\\mathbb{P}_r,\\mathbb{P}_\\theta) - 2\\log 2.\n\\] Consequently, if the discriminator has reached its optimum \\(D^*\\), training the generator is equivalent to minimizing the Jensen-Shannon divergence between the real and the approximated distributions."
  },
  {
    "objectID": "WGAN.html#motivation",
    "href": "WGAN.html#motivation",
    "title": "Wasserstein Generative Adversarial Network",
    "section": "Motivation",
    "text": "Motivation\nDespite great success in practical applications, the training of GANs is notoriously unstable. One of the main issues is called mode collapse, the phenomenon that a trained GAN generates samples of one single variety while ignoring other possible modes. It is widely believed that the main cause of mode collapse is the lack of control on the discriminator (Kushwaha, Nandi, et al. 2020). Philosophically, if the discriminator learns much faster than the generator, it criticizes all the samples produced by the generator, so that the generator does not know how to proceed. Conversely, if the discriminator learns much slower than the generator, it accepts all the results generated by the generator, which once again causes the similar issue. Hence, normal GAN training requires a careful adjustment in the relative learning speed of the generator and the discriminator. Numerically, we shall not train the discriminator till optimality before training the generator, despite the actual inf-sup structure of the optimization problem.\nThere are two main streams of ideas in the literature to augment the stability of GANs:\n\nMinimize an information divergence other than the Jensen-Shannon divergence.\nUse multiple generators to explicitly enforce GANs to capture diverse modes.\n\nWasserstein GANs take the first approach and use the Wasserstein distance (with \\(p=1\\)) instead of the Jensen-Shannon divergence. To understand what motivates WGANs, there are two main questions to answer:\n\nWhat is the advantage of the Wasserstein distance over the Jensen-Shannon divergence?\nHow to encode the minimization of the Wasserstein distance in the loss functions?"
  },
  {
    "objectID": "WGAN.html#advantage-of-wasserstein-distance",
    "href": "WGAN.html#advantage-of-wasserstein-distance",
    "title": "Wasserstein Generative Adversarial Network",
    "section": "Advantage of Wasserstein Distance",
    "text": "Advantage of Wasserstein Distance\nWe refer to a simple working example from (Arjovsky, Chintala, and Bottou 2017) that illustrates the advantage of using the Wasserstein distance \\(W(\\mathbb{P}_r,\\mathbb{P}_\\theta)\\).\nConsider the setting where \\(\\mathcal{X}= \\mathbb{R}^2\\). Let \\(S_\\theta := \\{\\theta\\}\\times [0,1]\\) denote a family of unit line segments parameterized by \\(\\theta\\). Clearly, each \\(S_\\theta\\) is a one-dimensional manifold within \\(\\mathcal{X}\\). Let \\(\\mathbb{P}_\\theta\\) be the uniform distribution on \\(S_\\theta\\) and \\(\\mathbb{P}_r = \\mathbb{P}_{\\theta = 0}\\). The optimal value of \\(\\theta\\) that guarantees \\(\\mathbb{P}_r = \\mathbb{P}_\\theta\\) is thus \\(0\\). We compare four differently defined information divergences between \\(\\mathbb{P}_r\\) and \\(\\mathbb{P}_\\theta\\):\n\nTotal variation: \\[\n\\text{TV}(\\mathbb{P}_0,\\mathbb{P}_\\theta) := \\sup_{A\\in\\mathscr{B}_{\\mathcal{X}}}|\\mathbb{P}_0(A) - \\mathbb{P}_\\theta(A)|,\n\\] where \\(\\mathscr{B}_{\\mathcal{X}}\\) denotes the Borel sigma field on \\(\\mathcal{X}\\). Since the supports \\(S_0\\) and \\(S_\\theta\\) are disjoint when \\(\\theta \\neq 0\\), the total variation attains its maximum value \\(1\\). Therefore, \\[\n\\text{TV}(\\mathbb{P}_0,\\mathbb{P}_\\theta) = \\begin{cases} 0 &\\text{if}\\ \\theta = 0\\\\ 1 & \\text{else}\\end{cases}.\n\\]\nKullback-Leibler divergence: \\[\n\\text{KL}(\\mathbb{P}_0||\\mathbb{P}_\\theta) := \\begin{cases} \\mathbb{E}_{\\mathbb{P}_\\theta} \\left(\\frac{\\text{d}\\mathbb{P}_0}{\\text{d}\\mathbb{P}_\\theta}\\log \\frac{\\text{d}\\mathbb{P}_0}{\\text{d}\\mathbb{P}_\\theta}\\right)& \\text{if}\\ \\mathbb{P}_0 &lt;&lt;\\mathbb{P}_\\theta\\\\ \\infty & \\text{else}\\end{cases},\n\\] where \\(&lt;&lt;\\) denotes the absolute continuity between measures. Since the supports \\(S_0\\) and \\(S_\\theta\\) are disjoint when \\(\\theta \\neq 0\\), absolute continuity fails and the KL divergence is infinite. Therefore, \\[\n\\text{KL}(\\mathbb{P}_0||\\mathbb{P}_\\theta) = \\begin{cases} 0 &\\text{if}\\ \\theta = 0\\\\ \\infty & \\text{else}\\end{cases}.\n\\]\nJensen-Shannon divergence: \\[\n\\text{JS}(\\mathbb{P}_0,\\mathbb{P}_\\theta) := \\frac{1}{2}\\text{KL}(\\mathbb{P}_0||\\frac{\\mathbb{P}_0 + \\mathbb{P}_\\theta}{2}) + \\frac{1}{2}\\text{KL}(\\mathbb{P}_\\theta||\\frac{\\mathbb{P}_0 + \\mathbb{P}_\\theta}{2}).\n\\] Note that \\(\\mathbb{P}_0&lt;&lt;\\frac{\\mathbb{P}_0 + \\mathbb{P}_\\theta}{2}\\), hence the Jensen-Shannon divergence is always finite. When \\(\\theta\\neq 0\\), we calculate the two Radon-Nikodym derivatives \\[\n\\frac{\\text{d}\\mathbb{P}_0}{\\text{d}\\frac{\\mathbb{P}_0 + \\mathbb{P}_\\theta}{2}} = 2\\mathbb{I}_{S_0},\\quad\n\\frac{\\text{d}\\mathbb{P}_\\theta}{\\text{d}\\frac{\\mathbb{P}_0 + \\mathbb{P}_\\theta}{2}} = 2\\mathbb{I}_{S_\\theta},\n\\] where \\(\\mathbb{I}_A\\) denotes the indicator of a set \\(A\\). Those conclusions could be verified from definitions \\[\n\\int_A 2\\mathbb{I}_{S_0}(x)\\,\\text{d}\\frac{\\mathbb{P}_0 + \\mathbb{P}_\\theta}{2}(x) = \\mathbb{P}_0(A\\cap S_0) + \\mathbb{P}_\\theta(A\\cap S_0) = \\mathbb{P}_0(A),\\ \\forall A\\in\\mathscr{B}_{\\mathcal{X}}.\n\\] Therefore, \\[\n\\text{JS}(\\mathbb{P}_0,\\mathbb{P}_\\theta) = \\begin{cases} 0 &\\text{if}\\ \\theta = 0\\\\ \\log 2 & \\text{else}\\end{cases}.\n\\]\nWasserstein distance with \\(p=1\\): \\[\nW(\\mathbb{P}_0,\\mathbb{P}_\\theta) := \\inf_{X\\sim \\mathbb{P}_0,Y\\sim\\mathbb{P}_\\theta} \\mathbb{E}\\|X - Y\\|_2.\n\\] From geometric intuition, \\(T(x) = x+\\theta\\) is the optimal transport map under the convex cost \\(c(x,y) = \\|x-y\\|_2\\). Therefore, \\[\nW(\\mathbb{P}_0,\\mathbb{P}_\\theta) = |\\theta|.\n\\]\n\nObviously, only the Wasserstein distance exhibits the continuity in parameter \\(\\theta\\), while other divergences have discontinuities at \\(0\\). This observation has been made rigorous in general cases (Arjovsky, Chintala, and Bottou 2017). The authors prove that if the generator \\(G_\\theta\\) is continuous in \\(\\theta\\), then so is \\(W(\\mathbb{P}_r,\\mathbb{P}_\\theta)\\). If the generator \\(G_\\theta\\) is locally Lipschitz in \\(\\theta\\), then so is \\(W(\\mathbb{P}_r,\\mathbb{P}_\\theta)\\) under mild regularity assumptions, which, by Rademacher’s theorem, implies that \\(W(\\mathbb{P}_r,\\mathbb{P}_\\theta)\\) is almost everywhere differentiable in \\(\\theta\\).\nThe continuity and differentiability w.r.t. the parameter is crucial in the training of GANs and is closely related to the issue of vanishing gradients. When the discriminator has reached its optimum and one gradient step of the generator is performed, the gradient actually refers to \\(\\nabla_{\\theta}[d(\\mathbb{P}_r,\\mathbb{P}_\\theta)]\\). In the example above, all divergences except the Wasserstein distance provide trivial (vanishing) gradients for the generator. By contrast, the Wasserstein distance provides a gradient that is \\(1\\) for positive \\(\\theta\\) and \\(-1\\) for negative \\(\\theta\\), which is always effective for the generator. Thanks to the physical interpretation of optimal transport, the Wasserstein distance, as a specific optimal-transport-based information divergence, greatly mitigates the issue of vanishing gradients for the generator."
  },
  {
    "objectID": "WGAN.html#construction-of-wgan",
    "href": "WGAN.html#construction-of-wgan",
    "title": "Wasserstein Generative Adversarial Network",
    "section": "Construction of WGAN",
    "text": "Construction of WGAN\nIn terms of numerical implementation, an inf-sup formulation of the optimization problem is required, as it clearly specifies the loss functions. Luckily, the Kantorovich-Rubinstein duality provides the representation: \\[\nW(\\mathbb{P}_r,\\mathbb{P}_\\theta) = \\sup_{\\|f\\|_L\\leq 1} \\mathbb{E}_{X\\sim \\mathbb{P}_r} f(X) - \\mathbb{E}_{Y\\sim\\mathbb{P}_\\theta}  f(Y),\n\\] where the supremum is taken over all Lipschitz functions \\(f\\) with Lipschitz constants no larger than \\(1\\). Substituting \\(f = \\frac{g}{K}\\) allows the relaxation in the Lipschitz constant: \\[\nK\\cdot W(\\mathbb{P}_r,\\mathbb{P}_\\theta) = \\sup_{\\|g\\|_L\\leq K} \\mathbb{E}_{X\\sim \\mathbb{P}_r} g(X) - \\mathbb{E}_{Y\\sim\\mathbb{P}_\\theta}  g(Y).\n\\] Therefore, the complete optimization problem of WGANs w.r.t. the parameterized generator \\(G_\\theta\\) and discriminator \\(D_w\\) is given by \\[\n\\inf_\\theta\\sup_{w:\\|D_w\\|_L\\leq K} \\mathbb{E}_{X\\sim \\mathbb{P}_r} D_w(X) - \\mathbb{E}_{Z\\sim\\mathbb{P}_Z}  D_w(G_\\theta(Z)).\n\\] The objective of this optimization problem serves as the loss functions in WGANs, shared by both the generator and the discriminator. One last piece of detail for the implementation of WGANs lies in the way to numerically impose the constraint \\(\\|D_w\\|_L\\leq K\\) for parameters \\(w\\). If \\(D_w\\) is parameterized by a feedforward neural network, each layer of the network consists of an affine mapping \\(x\\mapsto Wx + b\\) with weight \\(W\\), bias \\(b\\), and a mapping of the nonlinear activation function \\(\\sigma\\). Clearly, the affine mapping has Lipschitz constant \\(\\|W\\|\\), while the common activation functions, e.g., sigmoid, hyperbolic tangent, ReLU, etc, have Lipschitz constants \\(L_\\sigma&lt;\\infty\\). Therefore, the composition \\(x\\mapsto \\sigma(Wx+b)\\) has a Lipschitz constant \\(L_\\sigma\\|W\\|\\), which is uniform w.r.t. the trainable network parameters if \\(\\|W\\|\\) has a uniform upper bound, i.e., when \\(w\\) is restricted to a compact domain. As a result, WGANs impose the Lipschitz constraint by parameter clipping, e.g., restricting each component of \\(w\\) to take values in \\([-0.01,0.01]\\).\nWe remark that, by imposing the Lipschitz constraint, the discriminator is not allowed to saturate, thus providing effective gradients everywhere. As shown in the plot below, the GAN discriminator is too good at distinguishing two Gaussian distributions to provide effective gradients. In contrary, the WGAN discriminator (critic) with parameter clipping does not perform that well in distinguishing, but does provide effective gradients everywhere. Philosophically, the GAN discriminator is too smart that it demotivates the learning of the generator!\n\n\n\nThe comparisons of the behavior of optimal GAN discriminator and WGAN discriminator (critic) in dintinguishing two Gaussian distributions. The GAN discriminator saturates and provide trivial gradients within the main support of two Gaussian distributions. However, the WGAN discrinimator (critic) has a linear growth and provides effective gradients on the whole space. (Arjovsky, Chintala, and Bottou 2017)"
  },
  {
    "objectID": "WGAN.html#conclusions-and-future-studies",
    "href": "WGAN.html#conclusions-and-future-studies",
    "title": "Wasserstein Generative Adversarial Network",
    "section": "Conclusions and Future Studies",
    "text": "Conclusions and Future Studies\nTo conclude, WGANs improve the training stability of GANs by switching the minimization of the Jensen-Shannon divergence to that of the Wasserstein distance, which is continuous in terms of the parameter of the generator. Numerically, we make use of the Kantorovich-Rubinstein duality to keep the inf-sup structure of the optimization problem, and adopt parameter clipping to impose the Lipschitz continuity.\nAs pointed out in (Arjovsky, Chintala, and Bottou 2017), future studies can be conducted in the following directions:\n\nImpose the Lipschitz continuity of the neural network with a different technique, due to the subtleties in choosing the clipping hyperparameter.\nExplain why WGAN training is unstable when momentum based optimizers (like Adam) or high learning rates are used."
  },
  {
    "objectID": "DiscreteOT.html",
    "href": "DiscreteOT.html",
    "title": "Discrete Optimal Transport",
    "section": "",
    "text": "For a given space \\(X\\), we call a measure \\(\\alpha\\) on \\(X\\) a histogram if \\[ \\alpha = \\sum_{i=1}^{n} a_i \\delta_{x_i} , \\] where \\((a_1, \\ldots, a_n) \\in \\mathbb{R}_+^n\\), \\(\\sum \\limits_{i = 1}^n a_i = 1\\), and each \\(x_i \\in X\\). When the source measure \\(\\mu\\) and target measure \\(\\nu\\) are historgrams, the Monge problem and the Kantorovich problem may be stated as linear programs (Villani 2003), and solved using classical methods (Peyré and Cuturi 2001). This insight may be used to approximate the Wasserstein distances between general measures, by first discretizing the source and target with a known level of accuracy (a difficult problem), then computing the cost between the discrete measures."
  },
  {
    "objectID": "DiscreteOT.html#existence",
    "href": "DiscreteOT.html#existence",
    "title": "Discrete Optimal Transport",
    "section": "Existence",
    "text": "Existence\nFirst, consider the case \\(n &lt; m\\). In this case, we have more elements \\(\\{ y_j \\}\\) than elements \\(\\{ x_i \\}\\). As a result, the range of any transport map \\(T\\) does not equal \\(\\{ y_1, \\ldots, y_m \\}\\). Let \\(y_k\\) be an element such that \\(y_k \\notin T(x_1, \\ldots, x_n)\\). Notice that \\[ b_k =  \\sum \\limits_{i : T(x_i) = y_k} a_i = 0 , \\] which contradicts our assumption that each \\(b_j\\) is positive. Thus, no transport map exists, so the Monge problem does not have a solution.\nEven in the case \\(n \\geq m\\), existence is not guaranteed. For example, assume \\(n = m = 2\\), \\(X = Y = \\{ 1, 2 \\}\\). Define \\(x_1 = y_1 = 1, x_2 = y_2 = 2\\). Define \\[ \\alpha = \\frac{1}{3} \\delta_{x_1} + \\frac{2}{3} \\delta_{x_2}, \\beta = \\frac{1}{2} \\delta_{y_1} + \\frac{1}{2} \\delta_{y_2} . \\] There are no transport maps from \\(\\alpha\\) to \\(\\beta\\), hence the Monge problem does not have a solution."
  },
  {
    "objectID": "DiscreteOT.html#uniqueness",
    "href": "DiscreteOT.html#uniqueness",
    "title": "Discrete Optimal Transport",
    "section": "Uniqueness",
    "text": "Uniqueness\nThe Monge problem may have multiple minimizers. For example, assume \\(n = m = 2\\), \\(X = Y = \\mathbb{R}^2\\). Define \\[ x_1 = (0, 0), x_2 = (1, 1), y_1 = (1, 0), y_2 = (0, 1) . \\] Notice that \\(x_1\\) and \\(x_2\\) are the opposite corners of the unit square, as are \\(y_1\\) and \\(y_2\\). Define \\[ \\alpha = \\frac{1}{2} \\delta_{x_1} + \\frac{1}{2} \\delta_{x_2}, \\beta = \\frac{1}{2} \\delta_{y_1} + \\frac{1}{2} \\delta_{y_2} . \\] The only two transport maps are \\(T\\) and \\(T'\\), where \\[ T(x_1) = y_1, T(x_2) = y_2 , \\] \\[ T'(x_1) = y_2, T'(x_2) = y_1 . \\]\nWe consider the Monge problem with \\(c(x, y) = |x - y|\\). Notice that \\[ \\sum \\limits_{i = 1}^2 c(x_i, T(x_i)) = 2 , \\] \\[ \\sum \\limits_{i = 1}^2 c(x_i, T'(x_i)) = 2 . \\] Thus both transport maps are optimal, i.e. the Monge problem does not have a unique solution. This example is taken from (Peyré and Cuturi 2001)."
  },
  {
    "objectID": "DiscreteOT.html#existence-1",
    "href": "DiscreteOT.html#existence-1",
    "title": "Discrete Optimal Transport",
    "section": "Existence",
    "text": "Existence\nWe know there always exists an admissible coupling; take \\(P_{ij} = a_i b_j\\)."
  },
  {
    "objectID": "DiscreteOT.html#uniqueness-1",
    "href": "DiscreteOT.html#uniqueness-1",
    "title": "Discrete Optimal Transport",
    "section": "Uniqueness",
    "text": "Uniqueness\nAgain, optimal solutions may not be unique. Consider the example first consider in the discussion of the uniqueness of the Monge problem, i.e. the square. Notice that for any \\(i, j\\), \\(c(x_i, y_j) = 1\\). Thus, the Kantorovich problem reduces to\n\\[ \\min \\limits_{P \\in U(a, b)} \\sum \\limits_{i, j} P_{ij} . \\] Because \\(P \\in U(a, b)\\), we know that the entries of \\(P_{ij}\\) sum to one. Thus, for any admissible coupling \\(P\\), we have \\(\\sum \\limits_{i, j} c(x_i, y_j) P_{ij} = 1\\).\nConsider \\(P_1 = \\begin{bmatrix}\n\\frac{1}{2} & 0 \\\\\n0 & \\frac{1}{2}\n\\end{bmatrix}\\) and \\(P_2 = (P_1)^T\\). Both \\(P_1\\) and \\(P_2\\) are admissible couplings, and both achieve the minimum for the Kantorovich problem."
  },
  {
    "objectID": "DiscreteOT.html#the-dual-problem",
    "href": "DiscreteOT.html#the-dual-problem",
    "title": "Discrete Optimal Transport",
    "section": "The Dual Problem",
    "text": "The Dual Problem\nConsider the theorem mentioned in this article. In the discrete case, our dual problem reduces to \\[ \\max \\limits_{(f, g) \\in R(c)} \\left &lt; f, a \\right &gt; + \\left &lt; g, b \\right &gt; , \\] where \\(R(c) := \\left \\{ (f, g) \\in \\mathbb{R}^n \\times \\mathbb{R}^m :  \\text{ for all } 1 \\leq i \\leq n, 1 \\leq j \\leq m, f_i + g_j \\leq c_{ij} \\right \\}.\\) Again, we know that this maximum is achieved; see the article above for the rationale. We also know that the dual problem is equal to the primal problem."
  },
  {
    "objectID": "Gaussian_Measures.html",
    "href": "Gaussian_Measures.html",
    "title": "Gaussian Measures",
    "section": "",
    "text": "Gaussian Measures are ubiquitous throughout analysis, statistics, and many applied subjects. To a large extent this may be seen as a consequence of the central limit theorem, which in plain terms says that rescaled sums of sufficiently uncorrelated random variables converge to Gaussian variables. In particular quantities like height that depend on many variables will often times follow a gaussian distribution. For reasons we will see later, they also help us understand analysis in infinite dimensional spaces."
  },
  {
    "objectID": "Gaussian_Measures.html#lebesgue-measure-does-not-exist-in-infinite-dimensions",
    "href": "Gaussian_Measures.html#lebesgue-measure-does-not-exist-in-infinite-dimensions",
    "title": "Gaussian Measures",
    "section": "Lebesgue Measure Does not Exist in Infinite Dimensions",
    "text": "Lebesgue Measure Does not Exist in Infinite Dimensions\nHere is the formal statement that captures the fact that we can’t have a Lebesgue measure in infinite dimensions.\nTheorem: Let \\(X\\) be an infinite dimensional separable Banach space. If \\(\\mu\\) is a translation invariant Borel measure on \\(X\\) then either \\(\\mu\\) assigns infinite measure to each ball or it assigns measure \\(0\\) to each ball in \\(X\\).\nFor a full proof, see (Eldredge 2016) or (Stroock [2023]). Here is a sketch of the proof in the case where \\(X=l^2\\) is the space of square summable sequences. This special case, however, illustrates the key idea of the proof: namely that any ball contains infinitely many disjoint balls. Let \\(e_n\\) be the ``standard basis” in \\(l^2\\). That is, the entries of \\(e_n\\) are given by \\[\ne_n(m) = \\begin{cases}\n    0 & m\\neq n \\\\\n    1 & m=n\n\\end{cases}\n\\] Now observe that if \\(m\\neq n\\), \\(|e_n-e_m|=\\sqrt{2}\\) so if \\(B(x,r)\\) denotes the open ball of radius \\(r\\), we see that \\(\\left\\{B\\left(e_n,\\frac{\\sqrt{2}}{2}\\right)\\right\\}_{n=1}^\\infty\\) is a countable collection of disjoint open balls, each of which is contained in \\(B(0,2)\\) since if \\(x\\in B\\left(e_n,\\frac{\\sqrt{2}}{2}\\right)\\) then \\[\n    |x|\\leq |x-e_n|+|e_n|&lt;\\frac{\\sqrt{2}}{2}+1&lt;2\n\\] But then by additivity and translation invariance, \\[\n\\begin{align*}\n    \\mu(B(0,2)) &= \\sum_{n=1}^\\infty \\mu\\left(B\\left(e_n,\\frac{\\sqrt{2}}{2}\\right)\\right) \\\\\n    &= \\sum_{n=1}^\\infty \\mu\\left(B\\left(0,\\frac{\\sqrt{2}}{2}\\right)\\right)\n\\end{align*}\n\\] hence if \\(\\mu\\) assigns positive measure to \\(B\\left(0,\\frac{\\sqrt{2}}{2}\\right)\\) then it must give infinite measure to \\(B\\left(0,2\\right)\\). By translation invariance we can show that any ball of radius \\(2\\) must have positive measure. More generally we can use this argument with the radii appropriately rescales to show that if \\(\\mu\\) assigns positive measure to some ball, it must assign infinite measure to all balls."
  },
  {
    "objectID": "Gaussian_Measures.html#probability-measures-in-infinite-dimension",
    "href": "Gaussian_Measures.html#probability-measures-in-infinite-dimension",
    "title": "Gaussian Measures",
    "section": "Probability Measures in Infinite Dimension",
    "text": "Probability Measures in Infinite Dimension\nThroughout, suppose that \\(\\mu\\) is a borel probability measure on a a separable Banach space \\(X\\). In finite dimensions, we saw that the covariance matrix and mean characterized Gaussian measures. As usual, when we jump to infinite dimensions, matrices should be replaced with operators. Since any \\(f\\in X^*\\) is continuous, it is in particular borel measurable. In this setting, we define the covariance of two linear functionals as \\[\n    q(f,g) := \\langle f,g\\rangle_{L^2(X,\\mu)}=\\int_X f(x)g(x)d\\mu(x)\n\\] which is a bounded bilinear form. For gaussian measures on finite dimensional spaces, one can check that \\(q(f,g)=\\langle f,\\Sigma g\\rangle\\).\nSince there is no infinite dimensional Lebesgue measure, we’d hope to be able to define a Gaussian measure in terms of its Fourier transform. One can indeed define a Gaussian measure on \\(X\\) as one whose Fourier transform is \\(\\exp\\{-\\frac{1}{2}q(x,x)^2\\}\\) for a sufficiently nice bilinear form \\(q\\) on \\(X^*\\). The details of this definition are not relevant to us, but the theory of Fourier transforms of measures on Banach spaces (called characteristic functionals) is developed in (Bogachev 2006) Chapter 7 and (Kuo [1975]) Chapter 1. Intuitively what it means to say that \\(\\mu\\) is a Gaussian measure is that it “looks” Gaussian on every finite dimensional subspace. A more concrete definition that coincides with the definition in terms of the Fourier tranform is the following.\nDefinition: A borel probability measure \\(\\mu\\) on \\(X\\) is Gaussian if for every linear functional \\(f\\in X^*\\), \\(f_\\#\\mu\\) is a Gaussian measure on \\(\\mathbb{R}\\). Necesarily\nIf we specifically look at the case where \\(X\\) is a Hilbert space, more can be said about Gaussian measures on \\(X\\). Note that by the Riesz representation theorem, \\(H\\) is canonically identified with its dual, so \\(q\\) is identified with a unique bounded bilinear form on \\(H\\). Just like the corresponded outlined in fact (3) for the finite dimensional setting, there is the following correspondence.\nTheorem: (Kuo [1975]) There is a bijective correspondence between gaussian measures on \\(X\\) and positive semi-definite, self adjoint, trace class operators on \\(X\\). Specifically,\n\nFor each Gaussian measure \\(\\mu\\) on \\(X\\), its covariance form \\(q\\) is given by $q(f,g)=f, S_g$ for a unique positive semi-definite, self adjoint, trace class operator \\(S_\\mu\\).\nFor each positive semi-definite, self adjoint, trace class operator \\(S\\) on \\(X\\), there exists a unique mean \\(0\\) Gaussian measure \\(\\mu_S\\) with covariance form \\(q_S(f,g):=\\langle f,S g\\rangle_X\\).\n\nThe construction of \\(\\mu\\) from \\(q_S\\) is given by an infinite dimensional analogue of Bochner’s Theorem and Levy-Inversion. The upshot of this result is that we can construct whole families of Gaussian measures on Hilbert spaces very easily whereas it can be difficult for general Banach spaces."
  },
  {
    "objectID": "Gaussian_Measures.html#cameron-martin-theorem-integration-by-parts",
    "href": "Gaussian_Measures.html#cameron-martin-theorem-integration-by-parts",
    "title": "Gaussian Measures",
    "section": "Cameron-Martin Theorem & Integration by Parts",
    "text": "Cameron-Martin Theorem & Integration by Parts\nAn infinite dimensional analogue of equation (4) would be useful for giving us an integration by parts analogue and related analytic techniques. These are frequently used (not always rigorously) in Quantum Field Theory and the study of Gaussian processes (Albeverio, Høegh-Krohn, and Mazzucchi [2008]). The main theorem that answers this question is the Cameron-Martin theorem (see (Bogachev [1998]), (Kuo [1975]), or (Stroock [2023]) for a detailed exposition). Intuitively, this theorem says is that for almost every \\(h\\in X\\), \\(\\mu_h\\) and \\(\\mu\\) are mutually singular, while for very particular choices of \\(h\\) and analogue of equation (4) holds.\nNow for the technical statement. Note that for any continuous linear functional \\(f\\in X^*\\), \\[\n\\int_X|f(x)|^2 d\\mu(x) = \\int_\\mathbb{R}x^2d(f_\\#\\mu)(x) &lt;\\infty\n\\] since \\(f_\\#\\mu\\) is a Gaussian measure and \\(|x|^2\\) is integrable w.r.t. any Gaussian measure. In particular, there is an inclusion \\(X^*\\hookrightarrow L^2(X,\\mu)\\). Considering \\(X^*\\) as a subset of \\(L^2(X,\\mu)\\), let the completion \\(\\overline{X^*}^{L^2(X,\\mu)}\\) be denoted \\(K\\). Now define \\[\n    H:=\\{h\\in X: \\text{ the evaluation map }\\phi_h:X^*\\rightarrow \\mathbb{R} \\text{ given by } f\\mapsto f(h) \\text{ is continuous}\\}\n\\] By the continuous linear extension theorem it follows that for any \\(h\\in H\\), \\(\\phi_h\\) extends to a continuous linear functional on \\(K\\), the \\(L^2(X,\\mu)\\) closure of \\(X^*\\). Since \\(K\\) is a hilbert space with the \\(L^2(X,\\mu)\\) norm, it is identified with its dual. Thus we have a map \\(T:H\\rightarrow K\\) where \\(T(h)\\) is characterized by the fact that for any \\(f\\in X^*\\), \\(q(Th,f)=f(h)\\). One can prove that this is an isometry, hence it induces a complete inner product on \\(H\\), which we denote by \\(\\langle\\cdot,\\cdot \\rangle_H\\). We now have the language to state the following striking result.\nTheorem (Cameron-Martin): Let \\(\\mu\\) be a Gaussian measure on a a separable Banach space \\(X\\) with Cameron-Martin space \\(H\\). Then \\(\\mu(H)=0\\) and\n\nIf \\(h\\in H\\) then \\(\\mu_h &lt;&lt; \\mu\\) and \\[\n\\frac{d\\mu_h}{d\\mu} = \\exp\\left\\{-\\frac{1}{2}\\|h\\|_H^2+\\langle h,x\\rangle\\right\\}\n\\]\nIf \\(h\\in X\\setminus H\\) then \\(\\mu_h\\) and \\(\\mu\\) are mutually singular.\n\nThis makes precise the intuitive statement that equation (4) fails for \\(\\mu\\) almost every \\(h\\) For these pathological \\(h\\), there is no hope for an integration by parts formula or similar tools. For an explanation on the associated integration by parts formula (and why translation invariance leads to integration by parts) see (Driver 1991).\nThe situation is analogous to have a measure on \\(\\mathbb{R}^2\\) which is a Gaussian measure on the \\(x\\)-axis and zero elswhere. If we translate this measure along the \\(x\\) direction, the resulting measure will be mutually absolutely continuous. If we translate this measure by any other direction, however, the two measures will be mutually singular."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Contributors wanted!\nDo you want to help others learn about optimal transport? Do you need a concrete goal to motivate yourself to learn about a new topic? Please consider becoming a contributor to our wiki!\nYour contributions will be gratefully recognized in footers of each page. Please contact Katy Craig to receive an account.\nThis wiki is maintained by Katy Craig with help from the awesome students from Math 260L in Spring 202, Math 201A in Fall 2020, and Math 260J in Winter 2022."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Optimal Transport Wiki",
    "section": "",
    "text": "Welcome to the Optimal Transport Wiki!\nHere is a list of new article ideas. Here is a list of suggestions of articles to revise\nContact Katy Craig if you would like to contribute to this wiki.\n\nThe optimal transportation problem\n\nMonge Problem\nKantorovich Problem (has already been updated to quarto)\nOptimal Transport in One Dimension - will be revised by Yusen\nKantorovich Dual Problem (for general costs)\nKantorovich Dual Problem (for \\(c(x,y) = d(x,y)^2\\) where \\(d\\) is a metric) - Evan Tufte will revise\nRegularity of Optimal Transport Maps and the Monge-Ampére Equation on Riemannian Manifolds\n1-Wasserstein metric and generalizations\nOptimal Transport and Ricci curvature\n\n\n\nThe 2-Wasserstein Metric\n\nGeodesics and generalized geodesics\nFormal Riemannian Structure of the Wasserstein metric - Connor Marrs\nAsymptotic equivalence of W_2 and H^-1\n\n\n\nVariants of the optimal transport problem\n\nMartingale optimal transport and mathematical finance - will be edited by Haosheng Zhou and Qijin Shi\nMartingale optimal transport: dynamic formulation\nWasserstein barycenters and applications in image processing - Charles will revise\nWasserstein-like Metrics on Graphs\nContinuous time martingale OT and Skorohod Embedding - Qijin Shi\n\n\n\nNumerical methods for optimal transport\n\nDiscrete Optimal Transport\nAuction Algorithm\nSemidiscrete Optimal Transport\nSinkhorn’s Algorithm - Jack Pfaffinger will revise\nSliced Wasserstein Distance - Arie\nBack and Forth Method\n\n\n\nOptimal Transport and Statistics\n\nEstimation of transport maps - Evan Tufte, Chewi, Niles-Weed, Rigollet Ch.3\n\n\n\nWasserstein Gradient Flows\n\nProbability flow solution of the Fokker–Planck equation - Simone Betteti - Boffi and Vanden-Eijnden 2023\nBures-Wasserstein Gradient flows\nHellinger-Kantorvich Gradient flows - Djordje Nikolic\n\n\n\nMathematical foundations\n\nDual space of C_0(x) vs C_b(x)\nConvergence of Measures and Metrizability\nFenchel-Moreau and Primal/Dual Optimization Problems\nFenchel-Rockafellar and Linear Programming\nThe Moreau-Yosida Regularization\nGradient flows in Hilbert spaces\nThe continuity equation and Benamour Brenier formula\nIsoperimetric inequality and OMT\nGaussian Measures\nDynamic Optimal Transport\nGradient flows in metric spaces\n\n\n\nApplications of Optimal Transport\n\nMachine Learning\nShallow neural networks as Wasserstein gradient flows\nWasserstein Generative Adversarial Networks\nKnothe Maps and Conditional Sampling\n\n\n\nOther\n\nDistraction Recommendations\nNonlocal Equations Wiki\nProteopedia\nQuantum Information Wiki"
  },
  {
    "objectID": "Kantorovich_Problem.html",
    "href": "Kantorovich_Problem.html",
    "title": "Kantorovich Problem",
    "section": "",
    "text": "The Kantorovich problem (Villani 2003) is one of the two essential minimization problems in optimal transport (the other being the Monge problem). It is named after Russian mathematician and Nobel Laureate Leonid Kantorovich."
  },
  {
    "objectID": "Kantorovich_Problem.html#shipping-problem",
    "href": "Kantorovich_Problem.html#shipping-problem",
    "title": "Kantorovich Problem",
    "section": "Shipping problem",
    "text": "Shipping problem\nThe intuition behind the Kantorovich problem can be given by an explanation of optimizing shipments. Suppose there is a merchant who is attempting to ship items from one place to another. The merchant can hire trucks at some cost \\(c(x, y)\\) for each unit of merchandise which is shipped from point \\(x\\) to point \\(y\\). Now the shipper is approached by a mathematician, who claims that prices can be set such that they align with the shipper’s financial interests (Carlier 2010). This would be achieved by setting the price \\(\\phi(x)\\) and \\(\\phi(y)\\) such that the sum of \\(\\phi(x)\\) and \\(\\phi(y)\\) is always less than the cost \\(c(x, y)\\). This may even involve setting negative prices in certain cases. However, it can be shown that the shipper will spend almost as much as they would have if instead they opted for the original pricing method (Paris 2016)."
  },
  {
    "objectID": "Kantorovich_Problem.html#transport-plans",
    "href": "Kantorovich_Problem.html#transport-plans",
    "title": "Kantorovich Problem",
    "section": "Transport Plans",
    "text": "Transport Plans\nThe Monge problem was about the optimal way to rearrange mass (Craig 2020). Note that in the Monge formulation of the optimal transport problem, the mass cannot be split and thus it is mapped \\(x \\mapsto T(x)\\). When considering discrete cases, this results in problems when trying to establish maps T such that \\(T_{\\#} \\mu=\\nu\\). Kantorovich made the observation that the mass in question could be split, which makes the problem much easier to model  Craig, Katy. The Kantorovich Problem. Math 260L. Univ. of Ca. at Santa Barbara. Spring 2020 . Allowing the mass to be split results in a relaxation of the problem (e.g. half of the mass from \\(x_1\\) can go to \\(y_1\\) and half can go to \\(y_2\\), and so on). To model this consider \\(d \\pi(x, y)\\), which denotes the mass transported from x to y. This allows the mass to be moved to multiple places. Also consider \\(\\mu(A)\\) and \\(\\nu(B)\\): where the total mass taken from measurable set \\(A \\in X\\) must be equal to \\(\\mu(A)\\) and the total mass taken from measurable set \\(B \\in Y\\) must equal \\(\\nu(B)\\).\nThe constraints of the problem can be written in the following manner:\n\\[\n\\pi(A \\times Y)=\\mu(A)\n\\]\n\\[\n\\pi(X \\times B)=\\nu(B)\n\\]\nfor all measurable sets \\(A \\subseteq X, B \\subseteq Y\\). As such, we can interpret \\(\\pi( A\\times B)\\) as representing the amount of mass from \\(\\mu (A)\\) that is directed to \\(\\nu (B)\\)\nIf we have a measure \\(\\pi\\) that satisfies these constraints, then the set of such \\(\\pi\\) is referred to as \\(\\Pi(\\mu, \\nu)\\) – the set of transport plans between \\(\\mu\\) and \\(\\nu\\). Notice again that now we are dealing with transport plans instead of the transport maps that are used in the Monge formulation of the problem  Craig, Katy. The Kantorovich Problem. Math 260L. Univ. of Ca. at Santa Barbara. Spring 2020 ."
  },
  {
    "objectID": "Kantorovich_Problem.html#problem-statement",
    "href": "Kantorovich_Problem.html#problem-statement",
    "title": "Kantorovich Problem",
    "section": "Problem Statement",
    "text": "Problem Statement\nGiven \\(\\mu \\in \\mathcal{P}(X)\\) and \\(\\nu \\in \\mathcal{P}(Y)\\), solve\n\n\\(\\operatorname{min} \\mathbb{K}(\\pi):= \\operatorname{min} \\int_{X \\times Y} c(x, y) \\mathrm{d} \\pi(x, y)\\)\n\nover all such \\(\\pi \\in \\Pi(\\mu, \\nu)\\)\nAssuming there is a transport map \\(T^{\\dagger}: X \\rightarrow Y\\) for the Monge problem, we define \\(\\mathrm{d} \\pi(x, y)=\\mathrm{d} \\mu(x) \\delta_{y=T^{\\dagger}(x)}\\). Using this we can see that:\n\n\\(\\begin{aligned} \\pi(A \\times Y) &=\\int_{A} \\delta_{T^{\\dagger}(x) \\in Y} \\mathrm{d} \\mu(x)=\\mu(A) \\\\ \\pi(X \\times B) &=\\int_{X} \\delta_{T^{\\dagger}(x) \\in B} \\mathrm{d} \\mu(x)=T_{\\#}^{\\dagger} \\mu(B)=\\nu(B) \\end{aligned}\\)\n\nWe can see that \\(\\int_{X \\times Y} c(x, y) \\mathrm{d} \\pi(x, y)=\\int_{X} c\\left(x, T^{\\dagger}(x)\\right) \\mathrm{d} \\mu(x)\\)\nthus \\(\\inf \\mathbb{K}(\\pi) \\leq \\inf \\mathbb{M}(T)\\)."
  },
  {
    "objectID": "Kantorovich_Problem.html#kantorovich-duality",
    "href": "Kantorovich_Problem.html#kantorovich-duality",
    "title": "Kantorovich Problem",
    "section": "Kantorovich Duality",
    "text": "Kantorovich Duality\nSince the Kantorovich problem is a linear minimization problem with convex constraints it admits a dual problem. The astute reader may notice that this is a linear programming problem – Kantorovich is also considered to be the founder of linear programming."
  },
  {
    "objectID": "Kantorovich_Problem.html#calculus-of-variations-approach",
    "href": "Kantorovich_Problem.html#calculus-of-variations-approach",
    "title": "Kantorovich Problem",
    "section": "Calculus of Variations Approach",
    "text": "Calculus of Variations Approach\nUnder the right setting, one can show the Kantovorich problem indeed has a minimizer using the direct method of the calculus of variations. More specifically, if one turns to the narrow topology, then it turns out that we get compactness of the constraint set. Moreover, such a topology ensures us that our objective function is lower semi-continuous."
  },
  {
    "objectID": "Kantorovich_Problem.html#knott-smith-optimality-criterion",
    "href": "Kantorovich_Problem.html#knott-smith-optimality-criterion",
    "title": "Kantorovich Problem",
    "section": "Knott-Smith Optimality Criterion",
    "text": "Knott-Smith Optimality Criterion\nOne useful result we have that allows us to connect both the Monge and Kantorovich problems is the so-called the Knott-Smith Optimality Criterion (see below)."
  },
  {
    "objectID": "NewArticleIdeas.html",
    "href": "NewArticleIdeas.html",
    "title": "New Article Ideas",
    "section": "",
    "text": "Below, you can find a list of new article ideas and suggested references.\nFeel free to incorporate additional references! Please list all references you use at the bottom of your article.\nIf you choose to write about one of these ideas, let me know, and I will remove it from the list below. Want to write about something that’s not listed here? Great! Let me know, and I will suggest some references.\n\nVariants of Optimal Transport Problems\n\nThe \\(s\\)-Wasserstein metric for \\(s&lt;1\\) Craig and Yu, 2024, Santambrogio 3.3.2\nEntropic optimal transport, Chewi, Niles-Weed, Rigollet Ch.4 and 2\nConnections between entropic optimal transport and the Schrödinger bridge problem 1 - Ka Lok\nBrenier maps 3\nKnothe maps, Figalli-Glaudo (9-14), Carlier, et. al. ’08\n\n\n\nThe 2-Wasserstein Metric\n\nMulti-marginal optimal transport and density functional theory\nDisplacement convexity; Santambrogio (249-251,271-276); Villani (150-154) (make sure to cite existing wiki article on Geodesics and generalized geodesics)\n\n\n\nNumerical Methods for Optimal Transport\n\nComputing OT via Benamou-Brenier; Santambrogio (220-225); Peyré, Cuturi (102-108)\nWasserstein Barycenters; Santambrogio (215-218); Peyré, Cuturi (138-144)\n\n\n\nWasserstein Gradient Flows\n\nFundamentals of Wasserstein Gradient flows, Chewi, Niles-Weed, Rigollet (135-148) and Santambrogio, ‘Euclidean, Metric, and Wasserstein GFs’\n\n\n\nMathematical Foundations\n\n\nStatistical Foundations\n\nEstimation of Wasserstein distances, Chewi, Niles-Weed, Rigollet Ch.2\n\n\n\nApplications:\n\nOptimal transport methods in economics; see introduction of book by Galichon (I have a copy you can borrow) and 6\nQuantization and Lloyd’s algorithm 7, 8, 9\nTransformers as Wasserstein Gradient Flows; Chewi, Niles-Weed, Rigollet (195-200)\nInferring developmental trajectories of biological cells via optimal transport Waddington-OT, Schiebinger, et. al. 2019"
  },
  {
    "objectID": "Knothe_Maps_Conditional_Sampling.html",
    "href": "Knothe_Maps_Conditional_Sampling.html",
    "title": "Knothe Maps and Conditional Sampling",
    "section": "",
    "text": "A core problem of modern sampling is the approximation of high complexity distributions on \\(\\mathbb{R}^d\\). If \\(\\mu \\in \\mathcal{P}(\\mathbb{R}^d)\\) is some distribution of interest, and \\(\\nu \\in \\mathcal{P}(\\mathbb{R}^d)\\) is an easily computable reference distribution (typically a Gaussian), a transport map \\(t : \\mathbb{R}^d \\rightarrow \\mathbb{R}^d\\) satisfying \\(\\nu = t \\# \\mu\\) provides a link between distributions that can potentially allow for easier density estimation (Tabak and Turner 2013), inference (El Moselhy and Marzouk 2012), and generative modeling, particularly exhibited in WGANs.\nOptimal transport provides a widely used approach for computing such maps \\(t\\) through minimization of a relevant cost. However, the resulting map may not be amenable to fast computation, which is vitally important in some modern applications. Knothe maps provide a closely connected approach with certain benefits for a class of sampling problems. We focus on the efficient computation of Knothe maps, following the development of a recent algorithmic approach (Baptista, Marzouk, and Zahm 2023)."
  },
  {
    "objectID": "Knothe_Maps_Conditional_Sampling.html#definition",
    "href": "Knothe_Maps_Conditional_Sampling.html#definition",
    "title": "Knothe Maps and Conditional Sampling",
    "section": "Definition",
    "text": "Definition\nA Knothe-Rosenblatt map (Davis, Lii, and Politis 2011) is a transport map \\(S : \\mathbb{R}^d \\rightarrow \\mathbb{R}^d\\) that decomposes component-wise into the form:\n\\[\nS(\\mathbf{x}) = \\begin{bmatrix} S_1(x_1) \\\\ S_2(x_1, x_2) \\\\ \\vdots \\\\ S_d(x_1, \\dots, x_d)\\\\ \\end{bmatrix}\n\\] Each component function \\(S_i\\) may only depend on \\(\\mathbf{x}_{\\leq i} = (x_1, \\dots, x_i)\\) and must be increasing with respect to \\(x_i\\). The triangular structure of Knothe-Rosenblatt maps allows for efficient computation of both the inverse and the Jacobian, improving computational speed, while the increasing condition ensures \\(S_i\\) is an increasing transport map between the marginals \\(\\mu(x_i \\vert \\mathbf{x}_{&lt;i})\\) and \\(\\nu(x_i \\vert \\mathbf{x}_{&lt;i})\\), which allows for direct connection with conditional sampling.\nIn particular, for Jacobian computation, we have the explicit formula:\n\\[\n\\vert \\det \\nabla S(\\mathbf{x}) \\vert = \\prod_{i=1}^d \\partial_i S_i(\\mathbf{x}_{\\leq i})\n\\] Therefore, computation of the determinant of the Jacobian relies upon fast evaluation of partials for the increasing part of each component function, which is relatively quick to compute.\nIf \\(\\mu \\in \\mathcal{P}(\\mathbb{R}^d)\\) is absolutely continuous with respect to \\(\\nu \\in \\mathcal{P}(\\mathbb{R}^d)\\) with \\(\\nu\\) Gaussian, the Knothe-Rosenblatt map exists and is unique almost everywhere. (Bogachev, Kolesnikov, and Medvedev 2005)"
  },
  {
    "objectID": "Knothe_Maps_Conditional_Sampling.html#convergence-properties",
    "href": "Knothe_Maps_Conditional_Sampling.html#convergence-properties",
    "title": "Knothe Maps and Conditional Sampling",
    "section": "Convergence Properties",
    "text": "Convergence Properties\nOur eventual goal is to learn a close approximation of the Knothe-Rosenblatt map. Thus it is beneficial to examine convergence of maps \\(S\\) to the unique Knothe-Rosenblatt map \\(S_{KR}\\), assuming \\(\\nu\\) is a standard Gaussian on \\(\\mathbb{R}^d\\).\nKL divergence is an extremely popular statistical measure for quantification of the distance between two probability distributions in generative modeling. For the Knothe-Rosenblatt map, any triangular map \\(S\\) converges to \\(S_{KR}\\) in \\(L^2_{\\mu}\\) when \\(\\mathcal{D}_{KL}(\\mu \\vert \\vert S \\# \\nu) \\rightarrow 0\\).\nDefine the functional:\n\\[\n\\mathcal{J}_i(s) = \\int \\left( \\frac 1 2 s(\\mathbf{x}_{\\leq i})^2 - \\log \\vert \\partial_i s(\\mathbf{x}_{\\leq i}) \\vert  \\right) d\\mu\n\\] By decomposition of the Gaussian, one can write:\n\\[\n\\mathcal{D}_{KL}(\\mu \\vert \\vert S \\# \\nu) = \\sum_{i=1}^d \\mathcal{J}_i(S_i) - \\mathcal{J}_i(S_{KR,i})\n\\] For a given sample of data \\(\\{\\mathbf{X}^k\\}_{k=1}^n\\) from \\(\\mu\\), minimization of the above leads to a maximum likelihood estimator \\(\\hat{S}\\) for \\(S_{KR}\\):\n\\[\n\\hat{S} = \\arg \\max \\sum_{k=1}^n \\log S \\# \\nu (\\mathbf{X}^k)\n\\]\nwhere \\(S\\) are maximized over the space of triangular maps with \\(\\partial_i S_i &gt; 0\\) for all \\(i\\). This generates a convex optimization problem that can be parallelized in each component, as each \\(\\mathcal{J}_i\\) functional is independent."
  },
  {
    "objectID": "Knothe_Maps_Conditional_Sampling.html#rectification-operator",
    "href": "Knothe_Maps_Conditional_Sampling.html#rectification-operator",
    "title": "Knothe Maps and Conditional Sampling",
    "section": "Rectification Operator",
    "text": "Rectification Operator\nThe monotone condition on \\(S\\) is necessary for the formulation of triangular maps, but is inconvenient for learning, as most functional bases do not conveniently allow for this constraint to be satisfied. To solve this issue and allow for the use of standard functional bases, a rectifier functional \\(\\mathcal{R}\\) must be introduced, defined component-wise as the following:\n\\[\n\\mathcal{R}_i(f)(\\mathbf{x}_{\\leq i}) = f(\\mathbf{x}_{&lt;i},0) + \\int_0^{x_i} g\\left(\\partial_i f(\\mathbf{x}_{&lt;i}, t)\\right) dt\n\\]\nIf \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}^+\\) is a positive function, this transforms any \\(f\\) of sufficient smoothness into a function satisfying the increasing condition in the last variable component-wise.\n\n\n\nAn example of the action of the rectifier on a class of functions. This utilizes \\(g(x) = \\log(1 + \\exp(x))\\). As the function changes, corresponding changes to rectifier value are evident.\n\n\nThen the core component-wise learning of a Knothe-Rosenblatt map relies on the optimization problem:\n\\[\n\\min_{f\\in V_i} \\mathcal{J}_i(\\mathcal{R}_i(f))\n\\] where \\(V_i\\) is a suitable linear space of sufficiently smooth functions.\nUnder some additional assumptions on the choice of \\(g\\), and assuming the tails of the target distribution \\(\\mu\\) are Gaussian, there exists a unique global minimizer for the optimization problem using this rectifier, and the optimization landscape is relatively favorable. For a full treatment of the theoretical argument, refer to Section 3 of (Baptista, Marzouk, and Zahm 2023)."
  },
  {
    "objectID": "Knothe_Maps_Conditional_Sampling.html#functional-basis-expansion",
    "href": "Knothe_Maps_Conditional_Sampling.html#functional-basis-expansion",
    "title": "Knothe Maps and Conditional Sampling",
    "section": "Functional Basis Expansion",
    "text": "Functional Basis Expansion\nFor each \\(i\\), we approximate \\(f\\) by a particular chosen basis for a suitable function space. In particular, we represent:\n\\[\nf(\\mathbf{x}_{\\leq i}) = \\sum_{\\alpha \\in \\Lambda} c_{\\alpha} \\psi_{\\alpha}(\\mathbf{x}_{\\leq i})\n\\] In the above, \\(\\Lambda\\) forms the set of multi-indices \\(\\alpha = (\\alpha_1, \\alpha_2, \\dots, \\alpha_i) \\in \\mathbb{N}^i\\) with \\(\\vert\\Lambda \\vert = m\\), with \\(c_\\alpha \\in \\mathbb{R}\\) coefficients and \\(\\psi_{\\alpha} : \\mathbb{R}^i \\rightarrow \\mathbb{R}\\) basis functions for \\(V_i\\).\nThe basis functions \\(\\psi_{\\alpha}\\) are constructed as products of single variable functions:\n\\[\n\\psi_{\\alpha}(\\mathbf{x}_{\\leq i}) = \\prod_{j=1}^i \\psi^j_{\\alpha_j}(x_j)\n\\]\nSuitable choices for functional spaces include Hermite polynomials and Ricker wavelets, which provide expressive one- or two-parameter families of functions with well-known approximation properties that are suitable to many transport problems."
  },
  {
    "objectID": "Knothe_Maps_Conditional_Sampling.html#multi-index-set-construction",
    "href": "Knothe_Maps_Conditional_Sampling.html#multi-index-set-construction",
    "title": "Knothe Maps and Conditional Sampling",
    "section": "Multi-Index Set Construction",
    "text": "Multi-Index Set Construction\nNote that the richness of the functional basis is directly tied to the size \\(m\\) of the multi-index set \\(\\Lambda\\). Thus controlling this size gives a natural method to learn several different hierarchical expansions at varying levels of complexity. However, choosing which components to spend this finite budget of complexity on is a nontrivial problem.\nFortunately, a greedy algorithm is well suited to this task, as we have easily computable heuristics to inform each choice. In particular, we define \\(\\Lambda_0 = \\emptyset\\) and iteratively update:\n\\[\n\\Lambda_{t+1} = \\Lambda_t \\cup \\{\\alpha_t^*\\}\n\\] There are several necessary conditions for \\(\\alpha_t^*\\). First, \\(\\alpha_t^* \\notin \\Lambda_t\\) must hold. Second, we wish for the basis approximation to add complexity in a orderly manner, rather than adding random basis functions of high degree when one of lower degree will suffice. Thus we constrain the set \\(\\Lambda_t\\) to be downward closed:\n\\[\n\\alpha \\in \\Lambda_t \\text{ and } \\alpha' \\leq \\alpha \\implies \\alpha' \\in \\Lambda_t\n\\] We next define the margin of the set \\(\\Lambda_t\\). Let \\(e_j\\) denote the \\(j\\)-th canonical basis vector of \\(\\mathbb{N}^i\\):\n\\[\n\\Lambda_t^M = \\{\\alpha \\notin \\Lambda_t : \\exists j &gt; 0, \\alpha - e_j \\in \\Lambda_t\\}\n\\] Intuitively this means that the margin is any multi-index that is one shift away, in any direction, from the set \\(\\Lambda_t\\). The reduced margin is stronger in that the multi-index must be one shift away not in one, but in every direction:\n\\[\n\\Lambda_t^{RM} = \\{\\alpha \\notin \\Lambda_t : \\forall j &gt; 0, \\alpha - e_j \\in \\Lambda_t\\}\n\\] For our greedy algorithm, we add multi-indices via the following optimization procedure:\n\\[\n\\alpha_t^* \\in \\arg \\max_{\\alpha \\in \\Lambda_t^{RM}} \\vert \\nabla_{\\alpha} \\mathcal{J}_i(\\mathcal{R}_i(f_i)) \\vert\n\\]\nThat is, evaluate the derivative of the loss in the direction of each basis function under consideration, and choose to add the index with the largest derivative.\nBelow we illustrate this entire process for an example multi-index set:\n\n\n\nAn example of the hierarchical building of the set \\(\\Lambda_t\\) over time. At each iteration, the derivative of the loss is evaluated for all reduced margin squares (orange), and the one with highest magnitude is selected (green) and added to the next level of the set \\(\\Lambda_{t+1}\\) (blue)."
  },
  {
    "objectID": "Knothe_Maps_Conditional_Sampling.html#adaptive-transport-map-algorithm",
    "href": "Knothe_Maps_Conditional_Sampling.html#adaptive-transport-map-algorithm",
    "title": "Knothe Maps and Conditional Sampling",
    "section": "Adaptive Transport Map Algorithm",
    "text": "Adaptive Transport Map Algorithm\nUsing the above pieces, we can write the full algorithm for learning a map component \\(S_i\\) approximating the Knothe-Rosenblatt map component \\(S_{KR,i}\\):\nAlgorithm 1 (Baptista, Marzouk, and Zahm 2023): Estimate map component \\(S_i\\)\nInput: Training sample \\(\\{X^k_{1:i}\\}_{k=1}^{n}\\), cardinality \\(m\\) for \\(\\Lambda_t\\)\nInitialize: \\(\\Lambda_0 = \\emptyset\\), \\(f_0 = 0\\)\nfor \\(t = 0, \\dots, m-1\\):\n\nConstruct the reduced margin: \\(\\Lambda_t^{RM}\\)\nSelect the new multi-index:\n\n\\[\n\\alpha_t^* \\in \\arg\\max_{\\alpha \\in \\Lambda_t^{RM}} |\\nabla_{\\alpha} \\mathcal{J}_i(\\mathcal{R}_i(f_t))|\n\\]\n\nUpdate the active set: \\(\\Lambda_{t+1} = \\Lambda_t \\cup \\{\\alpha_t^*\\}\\)\nUpdate the approximation:\n\n\\[\nf_{t+1} = \\arg\\min_{f \\in \\text{span}\\{\\psi_{\\alpha} : \\alpha \\in \\Lambda_{t+1}\\}} \\mathcal{J}_i(\\mathcal{R}_i(f))\n\\]\nOutput: \\(\\hat{S}_i = R_i(f_m)\\)\nIn practice, the value of \\(m\\) can be considered a hyperparameter and optimized through cross-validation."
  },
  {
    "objectID": "Knothe_Maps_Conditional_Sampling.html#algorithm-application",
    "href": "Knothe_Maps_Conditional_Sampling.html#algorithm-application",
    "title": "Knothe Maps and Conditional Sampling",
    "section": "Algorithm Application",
    "text": "Algorithm Application\nMatlab code for learning Knothe-Rosenblatt maps is available on GitHub. From this repository, quick replication and extension of experiments is possible. Below we showcase the standard sampling problem: given \\(1000\\) points sampled from a true pdf, and using a reference measure that is standard Gaussian, approximate the true pdf by learning an approximation to the Knothe-Rosenblatt map.\n\n\n A total of \\(1000\\) sampled points from the given true distribution.\n\n\n The approximated distribution using the learned triangular map with Hermite polynomial basis."
  },
  {
    "objectID": "ArticlesToRevise.html",
    "href": "ArticlesToRevise.html",
    "title": "Suggestions of Articles to Revise",
    "section": "",
    "text": "Below, you can find a list of suggestions for articles to revise.\nIf you choose to revise one of these articles, let me know, and I will remove it from the list below.\n\nOptimal Transport in One Dimension - Yusen will revise - This article could benefit from a major reorganization, adding/removing some sections (such as the linear cost example), and stating the main theorem in a higher level of generality, as in Santambrogio Theorem 2.9 p63 of Optimal Transport for Applied Mathematicians\nKantorovich Dual Problem for General Costs - This article could benefit from editing throughout. It would be good to expand the final section on c-convcave functions, stating and explaining Santambrogio Proposition 1.11 p12 of Optimal Transport for Applied Mathematicians\nKantorovich Dual Problem (for c(x,y) = d(x,y)^2 where d is a metric) - Evan Tufte - This article could benefit from editing throughout, especially regarding the latex formatting. The condition that mu does not give mass to small sets needs to be corrected. This article should more thoroughly reference the other article on the Kantorovich dual probelm. It should prove the relationship between c-concave functions and convex conjugates, as in Santambrogio’s Proposition 1.21, p16 of Optimal Transport for Applied Mathematicians. The relationship between (DP) and (DP-var), as Santambrogio refers to them, needs to be explained. (You do not need to use the notation DP and DP-var.)\nWasserstein barycenters and applications in image processing - Charles will revise - This article could benefit from editing throughout, with more precise statements of the main results. It should also be revised to mention recent work on barycenters with positive and negative weights.\nDiscrete Optimal Transport - Charles will revise - This article could benefit from editing throughout. Several sections just have a few words as a placeholder and could be expanded. (The dual problem should be stated explicitly and a reference should be added to the wiki article on the dual problem.) The latex formatting could be simplified and made easier to read. Everything could be explained for general costs, rather than quadratic costs. The results of Exercise 25 could be included.\nSinkhorn’s Algorithm - Jack Pfaffinger will revise - This article could benefit from editing throughout. The wiki article on discrete optimal transport should be referenced. The interpretation of the Sinkhorn algorithm in terms of the corresponding dual probalm and in terms of convex projections should be explained. (See Peyre and Cuturi)\nSliced Wasserstein Distance - Arie - This article could benefit from editing throughout. Recent contributions by Kitagawa and Takatsu and Park and Slepcev should be summarized.\nGradient flows on Hilbert Spaces - The organization of this article could be greatly improved. Currently, there is an over emphacsis on the Moreau Yosida regularization. Also, the other wiki article on the MY regularization should be cited. The latex formatting could be improved throughout. The statements in the Examples and Applications section could be made more rigorous and more organized."
  },
  {
    "objectID": "DynamicMOT.html",
    "href": "DynamicMOT.html",
    "title": "Dynamic Formulation of Martingale Optimal Transport",
    "section": "",
    "text": "The following page mainly follows the first two sections of (Backhoff-Veraguas et al. 2020)."
  },
  {
    "objectID": "DynamicMOT.html#a-static-formulation",
    "href": "DynamicMOT.html#a-static-formulation",
    "title": "Dynamic Formulation of Martingale Optimal Transport",
    "section": "A static formulation",
    "text": "A static formulation\nA first observation is to claim the equivalence of \\(MT(\\mu, \\nu)\\) with the static formulation \\[\\begin{align}\n    WOT(\\mu, \\nu):= \\sup \\{\\int \\mu(dx) \\sup_{q\\in \\Pi(\\gamma^d, \\pi_x)}\\int b\\cdot m q(db, dm):\\{\\pi_x\\}_{x\\in \\Omega}, \\overline{\\pi_x} =x, \\nu(dy) = \\int \\pi_x(dy) \\mu(dx)\\}\n\\end{align}\\] where the supremum runs through all kernels (hence conditional distributions) from \\(\\mu\\) to \\(\\nu\\) with the mean property \\(\\overline{\\pi_x}:= \\int y \\pi_x(dy) = x\\). In terms of joint distributions, they corresponds precisely to all martingale couplings between \\(\\mu\\) and \\(\\nu\\).\n\nTheorem 1 (Equivalence between WOT and MT) For all \\(\\mu \\leq_c \\nu \\in P^2(\\Omega)\\), we have \\(MT(\\mu, \\nu) = WOT(\\mu, \\nu)\\).\n\n\nProof. \\((\\leq)\\). Going from dynamic to static is easier. Suppose we have a path \\(X_t = X_0 + \\int_0^t \\sigma_s dB_s\\) with \\(X_0\\sim \\mu\\) and \\(X_1\\in \\nu\\). The key observation is that by Ito’s formula, using super-script to denote the coordinate components, we have \\[\\begin{align}\n    d(X_t^i B_t^i) = X_t^i dB_t^i + B_t^i dX_t^i + d\\langle{X^i, B^i}\\rangle_t\n\\end{align}\\] where \\(d\\langle{X^i, B^i}\\rangle_t = \\sum_j d(\\sigma_{ij}B_t^j) dB_t^i= \\sigma_{ii}dt\\) is the cross variation between \\(X\\) and \\(B\\). Hence \\[\\begin{align}\nX_1\\cdot B_1 =     X_1\\cdot B_1 - X_0\\cdot B_0 = \\sum_i \\int_0^1 X_t^i dB_t^i + \\sum_{ij} \\int_0^1 B_t^i B_t^j \\sigma_{ij} dB_t^j + \\sum_i \\int_0^1 \\sigma_{ii}dt\n\\end{align}\\] Taking expectation gives the following frequently used formula \\[\n    \\mathbb{E}(X_1\\cdot B_1) = \\mathbb{E}\\int_0^1 tr(\\sigma_t)dt\n\\tag{1}\\] Using the tower law gives \\[\\begin{align}\n\\mathbb{E}(X_1\\cdot B_1) = \\mathbb{E}(\\mathbb{E}(X_1\\cdot B_1\\mid X_0)) = \\int \\mu(dx) \\int_{q\\in \\Pi(\\gamma, \\pi_x)} b\\cdot m q(dm, db) \\leq WOT(\\mu, \\nu)\n\\end{align}\\]\nConsidering all paths gives the inequality.\n\\((\\geq)\\). The remaining direction relies on an important construction. Suppose \\(\\pi\\in \\Pi(\\mu, \\nu)\\). Then for all \\(x\\in \\Omega\\), by Brenier’s theorem, there exists a unique convex gradient map \\(\\nabla F^x\\) such that \\(\\nabla F^x\\# \\gamma = \\pi_x\\) since \\(\\gamma\\) is absolutely continuous to \\(\\mathcal{L}eb\\) (recall \\(\\gamma\\) is the d-dim normal). Now we pick any filtration \\(\\mathcal{F}_t\\) and a standard Brownian motion \\(B_t\\) adapted to it and define \\[\\begin{align}\n    M_t^x:= E(\\nabla F^x (B_1) \\mid \\mathcal{F}_t^B) = E(\\nabla F^x (B_1) \\mid B_t)\n\\end{align}\\] where the second equality follows from the Markov property of \\(B_t\\). It is clearly that \\(M_t^x\\) is a martingale with \\(M_1^x = \\nabla F^x(B_1)\\sim \\pi_x\\) and \\(M_0^x = x\\). Now we pick \\(X\\sim \\mu\\) independent to \\(\\mathcal{F}_t\\). Then we define \\[\\begin{align}\n    M_t^X(\\omega) = M_t^{X(\\omega)}\n\\end{align}\\] which could be easily shown to be a martingale adapted to the filtration by \\(X\\) and \\(\\mathcal{F}_t\\) in which \\(X\\) is independent to \\(\\mathcal{F}_t^B\\). Let \\(\\sigma_t\\) be the volatility process of \\(M_t^X\\) (for instance given by the ). Then by Equation 1, we have \\[\\begin{align}\n     \\mathbb{E}\\int_0^1 tr(\\sigma_t)dt &= \\mathbb{E}(M_1^X\\cdot B_1) = \\mathbb{E}(\\mathbb{E}(\\nabla F^x(B_1)\\cdot B_1\\mid X)) = \\int \\mu(dx) \\mathbb{E}(\\nabla F^x(B_1)\\cdot B_1\\mid X = x) \\\\\n    & \\overset{X\\perp B}{=} \\int \\mu(dx) \\mathbb{E}(\\nabla F^x (B_1)\\cdot B_1)=\\int \\mu(dx)  \\sup_{q\\in \\Pi(\\gamma, \\pi_x)}\\int b\\cdot m q(dm, db)\\\\\n    &\\geq WOT(\\mu, \\nu)\n\\end{align}\\] in which the last equality follows from Brenier theorem for the choice of \\(\\nabla F^x\\). This of course implies that \\(MT(\\mu, \\nu)\\geq WOT(\\mu, \\nu)\\).\n\nWell-posedness with unique-in-law solution\nWith the equivalence between the static formulation and dynamic formulation one can then raise the well-established theory of the static case to the dynamic case.\n\nTheorem 2 (Well-posedness of MT and WOT) Let \\(\\mu\\leq_c \\nu\\in P^2(\\Omega)\\). Then we have\n\nThere exists a unique martingale coupling \\(\\pi^*\\) attaining \\(WOT(\\mu, \\nu)\\).\nThere exists a unique-in-law martingale \\(M_t\\) attaining \\(MT(\\mu, \\nu)\\).\n\n\n\nProof. \n\nThis follows from standard arguement so here we only give a sketch of proof. In particular recall that \\[\\begin{align}\nWOT(\\mu, \\nu):= \\sup \\{\\int \\mu(dx) \\sup_{q\\in \\Pi(\\gamma^d, \\pi_x)}\\int b\\cdot m q(db, dm):\\{\\pi_x\\}_{x\\in \\Omega}, \\overline{\\pi_x} =x, \\nu(dy) = \\int \\pi_x(dy) \\mu(dx)\\}\n\\end{align}\\] We can then make use of tightness property of martingale measures as well as strict concavity of the functional \\(H(\\eta):= \\sup_{q\\in \\Pi(\\gamma^d, \\eta)} \\int b\\cdot m d(db, dm)\\), which basically follows from that of the Wasserstein-2 metric, to claim the well-posedness of the static optimization.\nWe first consider the case where \\(\\mu = \\delta_x\\). Suppose \\(N_t\\) attains \\(MT(\\mu, \\nu)\\) with filtration \\(\\mathcal{F}_t\\) and Brownian motion \\(B_t\\). Then we have by Equation 1 \\[\\begin{align}\n\\mathbb{E}(N_1 B_1) =\\mathbb{E}\\int_0^1 tr(\\sigma_s) ds = MT(\\delta_x,\\nu) = WOT(\\delta_x, \\nu) = \\sup_{q\\in \\Pi(\\gamma, \\nu)}\\int b\\cdot n q(db, dn)\n\\end{align}\\] in which the last equality follows simply by definition of WOT. Since \\(N_1\\sim \\nu\\) and \\(B_1\\sim \\gamma\\), it follows that \\(N_t\\) induces the optimal coupling for the last quantity. It follows the by Brenier’s theorem we must have \\(N_1 = \\nabla F^x (B_1)\\). By the martingale property, we then have \\(N_t = E(\\nabla F^x(B_1)\\mid \\mathcal{F}_t)  = \\mathbb{E}(\\nabla F^x(B_1)\\mid B_t)\\) (recall that in the definition of MT, we are restricted to martingale over Brownian filtrations). This determines a unique law. For general \\(\\mu\\), as we are assuming the initial condition of the optimal process has to be independent to the remaining of the process, we already determine the law.\n\n\nProperty of stretched Brownian motions\nBecause of the well-posedness of \\(MT(\\mu, \\nu)\\), it deserves to give a name to the unique-in-law optimizer.\n\nDefinition 1 (Stretched Brownian Motions) Let \\(\\mu\\leq_c \\nu\\). Then we call the unique-in-law optimizer of \\(MT(\\mu, \\nu)\\) the stretched Brownian motion (sBm) from \\(\\mu\\) to \\(\\nu\\), which is a martingale \\(M_t\\) adapted to some Brownian filtration \\(\\mathcal{F}_t\\) and an independent \\(M_0\\sim \\mu\\) with \\(M_1\\sim \\nu\\).\n\n\nMarkov property of sBm\nTo deduce the Markov property of sBm we are going to establish a dynamic programming principle (DPP) for \\(MT(\\mu, \\nu)\\). To this end we define for \\(t\\in [0, 1]\\), \\[\\begin{align}\n    V(t, 1, \\mu, \\nu):= \\sup\\{\\mathbb{E}\\int_t^1 tr(\\sigma_s)ds: (M_t, \\sigma_t, \\mathcal{F}_t, \\mathbb{P}), M_t\\sim \\mu, M_1:=\\int_t^1 \\sigma_s dB_s \\sim \\nu\\}\n\\end{align}\\] with filtration conditions similar to that of \\(MT(\\mu, \\nu)\\) in which \\(M_t\\) has to be independent to the rest of the process. In particular, we have \\(V(0, 1, \\mu, \\nu) = MT(\\mu, \\nu)\\). The DPP is as follows\n\nTheorem 3 (DPP of \\(MT(\\mu, \\nu)\\)) Let \\(\\mu\\leq_c \\nu\\in P^2(\\Omega)\\). Then \\[\\begin{align}\n    V(0, 1, \\mu, \\nu) = \\sup\\{\\mathbb{E}(\\int_0^t tr(\\sigma_s)ds) + V(t, 1, \\mathcal{L}(M_t), \\nu): (M_0, \\sigma_t, \\mathcal{F}_t), M_0\\sim \\mu, M_t = \\int_0^t \\sigma_s dB_s\\}\n\\end{align}\\]\n\n\nProof. The \\(\\leq\\) direction is trivial. We consider the opposite direction. Let \\(M_t\\) be satisfying the condition on the right-hand-side so \\(dM_t = \\sigma_t dB_t\\) with \\(M_0\\sim \\mu\\). Now we want to build an optimal path from time \\(t\\) to \\(1\\). Clearly by similar arguement to sections 3 the value \\(V(t, 1,\\mathcal{L}(M_t), \\nu)\\) is attained by a unique-in-law processes with an independent initial condition. We now choose a Brownian filtration \\(\\mathcal{G}_t = \\sigma(W_t)\\) independent to \\(\\mathcal{F}_t\\). Let \\(\\sigma^{(2)}_t\\) be the volatility process of the dynamics: \\(dM^{(2)}_s = \\sigma^{(2)}_sdW_s\\). We set the initial condition to be \\(M_t^{(2)} = M_t\\). Since this initial condition is independent to the rest of the process, the resulting path gives a valid optimizer that attains the unique law. We then define \\[\\begin{align}\n    M_s^* := \\mathbb{1}_{s\\leq t}M_s + \\mathbb{1}_{s&gt;t} M_s^{(2)}\n\\end{align}\\] We now have to define a Browian motion for which the process is a martingale. Consider \\[\\begin{align}\n    B^*_s:= \\mathbb{1}_{s\\leq t} B_s + \\mathbb{1}_{s&gt;t} (W_s-W_t+ B_{t})\n\\end{align}\\] One can show that this is a Brownian motion! In addition, \\(M_s^*\\) is then a martingale with respect to this Brownian filtration (either by definition or one can show that \\(dM_s^* =  (\\sigma_s \\mathbb{1}_{s\\in [0, t]} + \\sigma_s^{(2)}\\mathbb{1}_{s\\in [t, 1]})dB_s^*\\)). It then follows that \\[\\begin{align}\n    \\mathbb{E}(\\int_0^t \\sigma_s dB_s) + V(t, 1, \\mathcal{L}(M_t), \\nu)=\\mathbb{E}(\\int_0^t \\sigma_s dB_s + \\int_t^1 \\sigma^{(2)}_s dW_s) = \\mathbb{E}(\\int_0^1 \\sigma^*_s dB_s^*)\\leq V(0, 1, \\mu, \\nu)\n\\end{align}\\] which concludes the proof.\n\nCorollary 1 The stretched Brownian motion from \\(\\mu\\) to \\(\\nu\\) is Markov\n\n\nProof. Fix \\(t\\) and a path of sBm \\(M_t\\). Then we can construct another sBm (identified by the same law) by first restricting \\(M_s\\) over \\([0, t]\\) and glue an independent path from \\(M_t\\) (given by the flexibility of filtration in the optimizer of \\(V\\)). It follows that conditioning on the path up to time \\(t\\) is the same as conditioning on the state at \\(t\\)."
  },
  {
    "objectID": "DynamicMOT.html#well-posedness-with-unique-in-law-solution",
    "href": "DynamicMOT.html#well-posedness-with-unique-in-law-solution",
    "title": "Dynamic Formulation of Martingale Optimal Transport",
    "section": "Well-posedness with unique-in-law solution",
    "text": "Well-posedness with unique-in-law solution\nWith the equivalence between the static formulation and dynamic formulation one can then raise the well-established theory of the static case to the dynamic case.\n\nTheorem 2 (Well-posedness of MT and WOT) Let \\(\\mu\\leq_c \\nu\\in P^2(\\Omega)\\). Then we have\n\nThere exists a unique martingale coupling \\(\\pi^*\\) attaining \\(WOT(\\mu, \\nu)\\).\nThere exists a unique-in-law martingale \\(M_t\\) attaining \\(MT(\\mu, \\nu)\\).\n\n\n\nProof. \n\nThis follows from standard arguement so here we only give a sketch of proof. In particular recall that \\[\\begin{align}\nWOT(\\mu, \\nu):= \\sup \\{\\int \\mu(dx) \\sup_{q\\in \\Pi(\\gamma^d, \\pi_x)}\\int b\\cdot m q(db, dm):\\{\\pi_x\\}_{x\\in \\Omega}, \\overline{\\pi_x} =x, \\nu(dy) = \\int \\pi_x(dy) \\mu(dx)\\}\n\\end{align}\\] We can then make use of tightness property of martingale measures as well as strict concavity of the functional \\(H(\\eta):= \\sup_{q\\in \\Pi(\\gamma^d, \\eta)} \\int b\\cdot m d(db, dm)\\), which basically follows from that of the Wasserstein-2 metric, to claim the well-posedness of the static optimization.\nWe first consider the case where \\(\\mu = \\delta_x\\). Suppose \\(N_t\\) attains \\(MT(\\mu, \\nu)\\) with filtration \\(\\mathcal{F}_t\\) and Brownian motion \\(B_t\\). Then we have by Equation 1 \\[\\begin{align}\n\\mathbb{E}(N_1 B_1) =\\mathbb{E}\\int_0^1 tr(\\sigma_s) ds = MT(\\delta_x,\\nu) = WOT(\\delta_x, \\nu) = \\sup_{q\\in \\Pi(\\gamma, \\nu)}\\int b\\cdot n q(db, dn)\n\\end{align}\\] in which the last equality follows simply by definition of WOT. Since \\(N_1\\sim \\nu\\) and \\(B_1\\sim \\gamma\\), it follows that \\(N_t\\) induces the optimal coupling for the last quantity. It follows the by Brenier’s theorem we must have \\(N_1 = \\nabla F^x (B_1)\\). By the martingale property, we then have \\(N_t = E(\\nabla F^x(B_1)\\mid \\mathcal{F}_t)  = \\mathbb{E}(\\nabla F^x(B_1)\\mid B_t)\\) (recall that in the definition of MT, we are restricted to martingale over Brownian filtrations). This determines a unique law. For general \\(\\mu\\), as we are assuming the initial condition of the optimal process has to be independent to the remaining of the process, we already determine the law.\n\n\nProperty of stretched Brownian motions\nBecause of the well-posedness of \\(MT(\\mu, \\nu)\\), it deserves to give a name to the unique-in-law optimizer.\n\nDefinition 1 (Stretched Brownian Motions) Let \\(\\mu\\leq_c \\nu\\). Then we call the unique-in-law optimizer of \\(MT(\\mu, \\nu)\\) the stretched Brownian motion (sBm) from \\(\\mu\\) to \\(\\nu\\), which is a martingale \\(M_t\\) adapted to some Brownian filtration \\(\\mathcal{F}_t\\) and an independent \\(M_0\\sim \\mu\\) with \\(M_1\\sim \\nu\\).\n\n\nMarkov property of sBm\nTo deduce the Markov property of sBm we are going to establish a dynamic programming principle (DPP) for \\(MT(\\mu, \\nu)\\). To this end we define for \\(t\\in [0, 1]\\), \\[\\begin{align}\n    V(t, 1, \\mu, \\nu):= \\sup\\{\\mathbb{E}\\int_t^1 tr(\\sigma_s)ds: (M_t, \\sigma_t, \\mathcal{F}_t, \\mathbb{P}), M_t\\sim \\mu, M_1:=\\int_t^1 \\sigma_s dB_s \\sim \\nu\\}\n\\end{align}\\] with filtration conditions similar to that of \\(MT(\\mu, \\nu)\\) in which \\(M_t\\) has to be independent to the rest of the process. In particular, we have \\(V(0, 1, \\mu, \\nu) = MT(\\mu, \\nu)\\). The DPP is as follows\n\nTheorem 3 (DPP of \\(MT(\\mu, \\nu)\\)) Let \\(\\mu\\leq_c \\nu\\in P^2(\\Omega)\\). Then \\[\\begin{align}\n    V(0, 1, \\mu, \\nu) = \\sup\\{\\mathbb{E}(\\int_0^t tr(\\sigma_s)ds) + V(t, 1, \\mathcal{L}(M_t), \\nu): (M_0, \\sigma_t, \\mathcal{F}_t), M_0\\sim \\mu, M_t = \\int_0^t \\sigma_s dB_s\\}\n\\end{align}\\]\n\n\nProof. The \\(\\leq\\) direction is trivial. We consider the opposite direction. Let \\(M_t\\) be satisfying the condition on the right-hand-side so \\(dM_t = \\sigma_t dB_t\\) with \\(M_0\\sim \\mu\\). Now we want to build an optimal path from time \\(t\\) to \\(1\\). Clearly by similar arguement to sections 3 the value \\(V(t, 1,\\mathcal{L}(M_t), \\nu)\\) is attained by a unique-in-law processes with an independent initial condition. We now choose a Brownian filtration \\(\\mathcal{G}_t = \\sigma(W_t)\\) independent to \\(\\mathcal{F}_t\\). Let \\(\\sigma^{(2)}_t\\) be the volatility process of the dynamics: \\(dM^{(2)}_s = \\sigma^{(2)}_sdW_s\\). We set the initial condition to be \\(M_t^{(2)} = M_t\\). Since this initial condition is independent to the rest of the process, the resulting path gives a valid optimizer that attains the unique law. We then define \\[\\begin{align}\n    M_s^* := \\mathbb{1}_{s\\leq t}M_s + \\mathbb{1}_{s&gt;t} M_s^{(2)}\n\\end{align}\\] We now have to define a Browian motion for which the process is a martingale. Consider \\[\\begin{align}\n    B^*_s:= \\mathbb{1}_{s\\leq t} B_s + \\mathbb{1}_{s&gt;t} (W_s-W_t+ B_{t})\n\\end{align}\\] One can show that this is a Brownian motion! In addition, \\(M_s^*\\) is then a martingale with respect to this Brownian filtration (either by definition or one can show that \\(dM_s^* =  (\\sigma_s \\mathbb{1}_{s\\in [0, t]} + \\sigma_s^{(2)}\\mathbb{1}_{s\\in [t, 1]})dB_s^*\\)). It then follows that \\[\\begin{align}\n    \\mathbb{E}(\\int_0^t \\sigma_s dB_s) + V(t, 1, \\mathcal{L}(M_t), \\nu)=\\mathbb{E}(\\int_0^t \\sigma_s dB_s + \\int_t^1 \\sigma^{(2)}_s dW_s) = \\mathbb{E}(\\int_0^1 \\sigma^*_s dB_s^*)\\leq V(0, 1, \\mu, \\nu)\n\\end{align}\\] which concludes the proof.\n\nCorollary 1 The stretched Brownian motion from \\(\\mu\\) to \\(\\nu\\) is Markov\n\n\nProof. Fix \\(t\\) and a path of sBm \\(M_t\\). Then we can construct another sBm (identified by the same law) by first restricting \\(M_s\\) over \\([0, t]\\) and glue an independent path from \\(M_t\\) (given by the flexibility of filtration in the optimizer of \\(V\\)). It follows that conditioning on the path up to time \\(t\\) is the same as conditioning on the state at \\(t\\)."
  },
  {
    "objectID": "DynamicMOT.html#markov-property-of-sbm",
    "href": "DynamicMOT.html#markov-property-of-sbm",
    "title": "Dynamic Formulation of Martingale Optimal Transport",
    "section": "Markov property of sBm",
    "text": "Markov property of sBm\nTo deduce the Markov property of sBm we are going to establish a dynamic programming principle (DPP) for \\(MT(\\mu, \\nu)\\). To this end we define for \\(t\\in [0, 1]\\), \\[\\begin{align}\n    V(t, 1, \\mu, \\nu):= \\sup\\{\\mathbb{E}\\int_t^1 tr(\\sigma_s)ds: (M_t, \\sigma_t, \\mathcal{F}_t, \\mathbb{P}), M_t\\sim \\mu, M_1:=\\int_t^1 \\sigma_s dB_s \\sim \\nu\\}\n\\end{align}\\] with filtration conditions similar to that of \\(MT(\\mu, \\nu)\\) in which \\(M_t\\) has to be independent to the rest of the process. In particular, we have \\(V(0, 1, \\mu, \\nu) = MT(\\mu, \\nu)\\). The DPP is as follows\n\nTheorem 3 (DPP of \\(MT(\\mu, \\nu)\\)) Let \\(\\mu\\leq_c \\nu\\in P^2(\\Omega)\\). Then \\[\\begin{align}\n    V(0, 1, \\mu, \\nu) = \\sup\\{\\mathbb{E}(\\int_0^t tr(\\sigma_s)ds) + V(t, 1, \\mathcal{L}(M_t), \\nu): (M_0, \\sigma_t, \\mathcal{F}_t), M_0\\sim \\mu, M_t = \\int_0^t \\sigma_s dB_s\\}\n\\end{align}\\]\n\n\nProof. The \\(\\leq\\) direction is trivial. We consider the opposite direction. Let \\(M_t\\) be satisfying the condition on the right-hand-side so \\(dM_t = \\sigma_t dB_t\\) with \\(M_0\\sim \\mu\\). Now we want to build an optimal path from time \\(t\\) to \\(1\\). Clearly by similar arguement to sections 3 the value \\(V(t, 1,\\mathcal{L}(M_t), \\nu)\\) is attained by a unique-in-law processes with an independent initial condition. We now choose a Brownian filtration \\(\\mathcal{G}_t = \\sigma(W_t)\\) independent to \\(\\mathcal{F}_t\\). Let \\(\\sigma^{(2)}_t\\) be the volatility process of the dynamics: \\(dM^{(2)}_s = \\sigma^{(2)}_sdW_s\\). We set the initial condition to be \\(M_t^{(2)} = M_t\\). Since this initial condition is independent to the rest of the process, the resulting path gives a valid optimizer that attains the unique law. We then define \\[\\begin{align}\n    M_s^* := \\mathbb{1}_{s\\leq t}M_s + \\mathbb{1}_{s&gt;t} M_s^{(2)}\n\\end{align}\\] We now have to define a Browian motion for which the process is a martingale. Consider \\[\\begin{align}\n    B^*_s:= \\mathbb{1}_{s\\leq t} B_s + \\mathbb{1}_{s&gt;t} (W_s-W_t+ B_{t})\n\\end{align}\\] One can show that this is a Brownian motion! In addition, \\(M_s^*\\) is then a martingale with respect to this Brownian filtration (either by definition or one can show that \\(dM_s^* =  (\\sigma_s \\mathbb{1}_{s\\in [0, t]} + \\sigma_s^{(2)}\\mathbb{1}_{s\\in [t, 1]})dB_s^*\\)). It then follows that \\[\\begin{align}\n    \\mathbb{E}(\\int_0^t \\sigma_s dB_s) + V(t, 1, \\mathcal{L}(M_t), \\nu)=\\mathbb{E}(\\int_0^t \\sigma_s dB_s + \\int_t^1 \\sigma^{(2)}_s dW_s) = \\mathbb{E}(\\int_0^1 \\sigma^*_s dB_s^*)\\leq V(0, 1, \\mu, \\nu)\n\\end{align}\\] which concludes the proof.\n\nCorollary 1 The stretched Brownian motion from \\(\\mu\\) to \\(\\nu\\) is Markov\n\n\nProof. Fix \\(t\\) and a path of sBm \\(M_t\\). Then we can construct another sBm (identified by the same law) by first restricting \\(M_s\\) over \\([0, t]\\) and glue an independent path from \\(M_t\\) (given by the flexibility of filtration in the optimizer of \\(V\\)). It follows that conditioning on the path up to time \\(t\\) is the same as conditioning on the state at \\(t\\)."
  },
  {
    "objectID": "backandfortharticle.html",
    "href": "backandfortharticle.html",
    "title": "The Back and Forth Method",
    "section": "",
    "text": "The Back and Forth Method is an iterative method introduced by Jacobs and Léger in (Jacobs and Léger 2020) for solving the optimal transport problem for a class of strictly convex costs, including quadratic and \\(p\\)-power costs. This article closely follows (Jacobs and Léger 2020).\n\nPreliminaries\nLet \\(\\Omega \\subset \\mathbb{R}^{d}\\), be convex and compact. A cost on \\(\\Omega\\) is a continuous function \\(c: \\Omega \\times \\Omega \\rightarrow \\mathbb{R}\\). However, for this approach we will only focus on the case in which \\[ c(x, y) = h(y-x) \\] for some strictly convex and even function \\(h: \\mathbb{R}^d \\rightarrow \\mathbb{R}\\). Let \\(\\mu\\) and \\(\\nu\\) be probability measures. We will concentrate on the special case where \\(\\mu\\) and \\(\\nu\\) are absolutely continuous with respect to Lebesgue measure. Because of this, we may commit a standard abuse of notation and identify a measure with its density function.\n\n\nThe Optimal Transport Problem Background\nGiven measures \\(\\mu\\) and \\(\\nu\\) which are supported in \\(\\Omega\\), we can define the Monge formulation of the optimal transport problem (also known simply as the Monge Problem) as: \\[ C(\\mu, \\nu) = \\inf_{T} \\int_{\\Omega}c(x, T(x))d\\mu(x) \\] where this infimum runs over maps \\(T: \\Omega \\rightarrow \\Omega\\) such that \\(T \\# \\mu = \\nu\\), where \\(T \\# \\mu\\) is the pushforward of \\(\\mu\\) under \\(T\\). The pushforward condition can be characterized by defining the integral of the pushforward measure against continuous test functions \\(f: \\Omega \\rightarrow \\mathbb{R}\\): \\[ \\int_{\\Omega}f(y)d(T \\# \\mu)(y) = \\int_{\\Omega} f(T(x))d\\mu(x) . \\]\nIf \\(\\mu\\) and \\(\\nu\\) are absolutely continuous with respect to Lebesgue, there exists a unique optimal map \\(T_{*}\\) which pushed \\(\\mu\\) to \\(\\nu\\), and its inverse \\(T_{*}^{-1}\\) is the optimal map that pushes \\(\\nu\\) to \\(\\mu\\) (Gangbo 1995).\nThe pushforward constraint \\(T\\#\\mu = \\nu\\) holds if and only if \\[ \\int_{\\Omega}\\phi(T(x))d\\mu(x) = \\int_{\\Omega} \\phi(y) d\\nu(y) \\] for every continuous function \\(\\phi\\).\nIt follows that: \\[ \\inf_{T \\# \\mu = \\nu} \\int_{\\Omega} c(x, T(x))d\\mu(x) = \\inf_{T} \\sup_{\\phi} \\int_{\\Omega} c(x, T(x)) d \\mu(x) - \\phi(T(x))d\\mu(x) + \\int_{\\Omega}\\phi(y)d\\nu(y) . \\]\nIf \\(\\mu\\) is absolutely continuous, then we can interchange the supremum and infimum (Santambrogio 2015) and obtain: \\[ \\sup_{\\phi} \\inf_{T} \\int_{\\Omega}\\left( c(x, T(x)) - \\phi(T(x)) \\right) d \\mu(x) + \\int_{\\Omega}\\phi(y) d\\nu(y) . \\]\nFrom here, we can see that the term \\(\\inf_{T(x)} c(x, T(x)) - \\phi(T(x))\\) is important for the dual problem. To further analyze this, we will introduce a new operation, called the \\(c\\)-transform, which can be seen as a generalization of the Legendre transform.\nDefinition: Given a continuous function \\(\\phi: \\Omega \\rightarrow \\mathbb{R}\\), we define its \\(c\\)-transform \\(\\phi^c : \\Omega \\rightarrow \\mathbb{R}\\) by \\[ \\phi^{c} (x) = \\inf_{y \\in \\Omega} c(x, y) - \\phi(y) . \\]\nWe can now introduce the Kantorovich dual functional \\[ J(\\phi) = \\int_{\\Omega} \\phi d \\nu + \\int_{\\Omega} \\phi^{c} d\\mu . \\] It can be seen from above that \\[ C(\\mu, \\nu)= \\sup_{\\phi}J(\\phi) \\] where the supremum runs over all continuous functions \\(\\phi: \\Omega \\rightarrow \\mathbb{R}\\).\n\n\nGradient Ascent\nLet \\((\\mathcal{H}, || \\cdot||_{\\mathcal{H}})\\) be a separable Hilbert space and suppose that \\(F\\) is a smooth convex functional \\(F: \\mathcal{H} \\rightarrow \\mathbb{R}\\).\nDefinition: Given a point \\(\\phi \\in \\mathcal{H}\\), we say that a bounded linear map \\(\\delta F_{\\phi} : \\mathcal{H} \\rightarrow \\mathbb{R}\\) is the Fréchet derivative of \\(F\\) at \\(\\phi\\) if \\[ \\lim_{||h||_{\\mathcal{H}} \\rightarrow 0} \\frac{||F(\\phi + h) - F(\\phi) - \\delta F_{\\delta}(h)||_{\\mathcal{H}}}{||h||_{\\mathcal{H}}} = 0 . \\]\nDefinition: Let \\(\\langle \\cdot, \\cdot \\rangle_{\\mathcal{H}}\\) be the inner product associated with the Hilbert space \\(\\mathcal{H}\\). We say that a map \\(\\nabla_{\\mathcal{H}} F : \\mathcal{H} \\rightarrow \\mathcal{H}\\) is the \\(\\mathcal{H}\\)-gradient of \\(F\\) if \\[ \\langle \\nabla_{\\mathcal{H}} F(\\phi), h \\rangle_{\\mathcal{H}} = \\delta F_{\\phi}(h) \\] for all \\((\\phi, h) \\in \\mathcal{H} \\times \\mathcal{H}\\).\nTo define the back-and-forth method we will need to compute the gradient with respect to \\(\\dot{H^{1}}\\), where \\(\\dot{H^{1}}(\\Omega)\\) is the Hilbert space \\[ \\dot{H^{1}}(\\Omega) = \\{ \\varphi : \\Omega \\rightarrow \\mathbb{R} : \\int_{\\Omega} \\varphi(x)dx = 0 \\text{ and } \\int_{\\Omega} \\|\\nabla \\varphi(x)||^{2}dx &lt; \\infty \\} \\] equipped with the inner product \\[ \\langle \\varphi_{1}, \\varphi_2 \\rangle_{\\dot{H^{1}}(\\Omega)} = \\int_{\\Omega} \\nabla \\varphi_{1}(x) \\cdot \\nabla \\varphi_{2}(x) dx . \\]\n\n\nThe Back and Forth Method\nWe will consider the dual functional in the following equivalent forms \\[ J(\\phi) = \\int_{\\Omega} \\phi d \\nu + \\int_{\\Omega} \\phi^{c} d\\mu \\] and \\[ I(\\psi) = \\int_{\\Omega} \\psi^{c} d \\nu + \\int_{\\Omega} \\psi d\\mu . \\]\nNote that these two functionals are identical, just with the roles of \\(\\mu\\) and \\(\\nu\\) are flipped.\nWe are now ready to define the back-and-forth method.\n\n\nThe Back and Forth Algorithm\nAlgorithm 1: The Back and Forth Method\nGiven probability densities \\(\\mu\\) and \\(\\nu\\), set \\(\\phi_0 = 0, \\psi_0 = 0\\), and iterate:\n\\[\n\\begin{aligned}\n    \\phi_{n+\\frac{1}{2}} &\\leftarrow \\phi_n + \\sigma \\nabla_{\\dot{H}^1} J(\\phi_n), \\\\\n    \\psi_{n+\\frac{1}{2}} &\\leftarrow (\\phi_{n+\\frac{1}{2}})^c, \\\\\n    \\psi_{n+1} &\\leftarrow \\psi_{n+\\frac{1}{2}} + \\sigma \\nabla_{\\dot{H}^1} I(\\psi_{n+\\frac{1}{2}}), \\\\\n    \\phi_{n+1} &\\leftarrow (\\psi_{n+1})^c.\n\\end{aligned}\n\\]\nWe will note that given two probability measures supported on a discrete grid with \\(n\\) points, we compute the optimal map using \\(O(n)\\) storage space and \\(O(n \\log(n))\\) operations per iteration, with an approximately exponential convergence rate. For more information and numerical examples, please see (Jacobs and Léger 2020).\n\n\n\n\n\nReferences\n\nGangbo, Wilfrid. 1995. “Quelques Problèmes d’analyse Non Convexe. Habilitation à Diriger Des Recherches En Mathématiques.” Habilitation. Université de Metz.\n\n\nJacobs, Matt, and Flavien Léger. 2020. “A Fast Approach to Optimal Transport: The Back and Forth Method.” https://arxiv.org/abs/1905.12154.\n\n\nSantambrogio, Filippo. 2015. Optimal Transport for Applied Mathematicians. Vol. 87. Progress in Nonlinear Differential Equations and Their Applications. Cham: Birkhäuser/Springer. https://doi.org/10.1007/978-3-319-20828-2."
  },
  {
    "objectID": "Bures-Wasserstein Gradient Flows.html",
    "href": "Bures-Wasserstein Gradient Flows.html",
    "title": "Bures-Wasserstein Gradient Flow",
    "section": "",
    "text": "The Bures-Wasserstein gradient flow is a Wasserstein gradient flow in the space of Gaussian measures. Descriptions of Bures-Wasserstein gradient flows take advantage of the simplicity of transport maps between Gaussian distributions in order to provide an alternate, computationally tractable viewpoint on certain types of Wasserstein gradient flows (Chen, Georgiou, and Tannenbaum 2019; Delon and Desolneux 2020)."
  },
  {
    "objectID": "Bures-Wasserstein Gradient Flows.html#variational-characterization",
    "href": "Bures-Wasserstein Gradient Flows.html#variational-characterization",
    "title": "Bures-Wasserstein Gradient Flow",
    "section": "Variational Characterization",
    "text": "Variational Characterization\nLet \\(\\mathcal{F} : \\mathcal{P}_{2,\\text{ac}}(\\mathbb R^d)\\rightarrow \\mathbb R\\) be a functional with first variation \\(\\delta \\mathcal{F}(\\mu)\\) at \\(\\mu = \\mathcal{N}(m,\\Sigma) \\in \\text{BW}(\\mathbb R^d)\\). Then the Bures-Wasserstein gradient of \\(\\mathcal{F}\\) at \\(\\mu\\) is the affine mapping \\[x \\mapsto \\bigg( \\int\\nabla^2  \\delta \\mathcal{F}(\\mu) d\\mu\\bigg)(x-m) + \\int\\nabla  \\delta \\mathcal{F}(\\mu) d\\mu\\] where \\(m\\) is the mean of \\(\\mu\\).\n\nCharacterization in terms of Mean and Variance\nThe Bures-Wasserstein gradient flow of the functional \\(\\mathcal{F}\\) is the curve \\((\\mu_t=\\mathcal{N}(m_t,\\Sigma_t))_{t \\geq 0}\\), where \\[\\begin{align*}\n        \\dot{m}_t &= - \\mathbb E\\nabla  \\delta \\mathcal{F}(\\mu_t) (X_t)\\\\\n        \\dot{\\Sigma}_t &= -\\mathbb E\\nabla^2  \\delta \\mathcal{F}(\\mu_t) (X_t)\\Sigma_t - \\Sigma_t \\mathbb E\\nabla^2  \\delta \\mathcal{F}(\\mu_t) (X_t)\n\\end{align*}\\] where \\(X_t \\sim \\mu_t\\).\nThe theorem stated above provides a characterization of the Bures-Wasserstein gradient flow based entirely on the mean and covariance of each measure \\(\\mu_t\\) in the gradient flow. This can also be viewed as a Lagrangian or particle-based interpretation of the gradient flow."
  },
  {
    "objectID": "Bures-Wasserstein Gradient Flows.html#wasserstein-gradients-flows-over-gaussian-mixture-models",
    "href": "Bures-Wasserstein Gradient Flows.html#wasserstein-gradients-flows-over-gaussian-mixture-models",
    "title": "Bures-Wasserstein Gradient Flow",
    "section": "Wasserstein Gradients flows over Gaussian Mixture Models",
    "text": "Wasserstein Gradients flows over Gaussian Mixture Models\nBures-Wasserstein gradients can be used to provide an alternative interpretation of gradient flows in \\(\\mathcal{P}_{2,\\text{ac}}(\\mathbb R^d)\\) by treating probability measures as mixtures of (possibly degenerate) Gaussians. Traditionally, a Gaussian mixture is a measure whose density is a convex combination of Gaussian densities. This is generalized by defining a Gaussian mixture in terms of what is known as a mixing measure \\(\\nu \\in \\mathcal{P}_2(\\text{BW}(\\mathbb R^d)) \\cong \\mathcal{P}_2(\\mathbb R^d \\times S^d_{++})\\), so that the corresponding Gaussian mixture \\(G_{\\nu}\\) is defined as \\(G_{\\nu} = \\int \\mathcal{N}(m,\\Sigma) \\nu(dm, d\\Sigma)\\). One may treat \\(\\nu\\) as the distribution of mean and covariance variables \\(m, \\Sigma\\), i.e \\(\\nu = \\text{law}(m,\\Sigma)\\) for some random variables \\(m\\) and \\(\\Sigma\\).\nA Wasserstein metric can be defined on \\(\\mathcal{P}_2(\\text{BW}(\\mathbb R^d))\\) in the same fashion as \\(\\mathcal{P}_2(\\mathbb R^d)\\) is defined, with the underlying metric space changed but the fundamental concepts unaltered. The mapping \\(\\nu \\mapsto G_{\\nu}\\) provides a surjective mapping from \\(\\mathcal{P}_2(\\text{BW}(\\mathbb R^d))\\) to \\(\\mathcal{P}_2(\\mathbb R^d)\\), which allows us to reinterpret gradient flows of a functional \\(\\mathcal{F} : \\mathcal{P}_2(\\mathbb R^d)\\rightarrow \\mathbb R\\) in terms of the functional \\(\\mathcal{G}: \\nu \\mapsto \\mathcal{F}(G_{\\nu})\\) via the proposition below.\n\nGradient Flow Expression in \\(\\mathcal{P}_2(\\text{BW}(\\mathbb R^d))\\)\nLet \\(\\nu \\in \\mathcal{P}_2(\\text{BW}(\\mathbb R^d))\\) be given and let \\(G_{\\nu} = \\int \\mathcal{N}(m,\\Sigma) \\nu(dm, d\\Sigma)\\) denote the Gaussian mixture corresponding to \\(\\nu\\). Let \\(\\mathcal{F}\\) be a functional over \\(\\mathcal{P}_2(\\mathbb R^d)\\) and let \\(\\mathcal{G}\\) be the functional over \\(\\mathcal{P}_2(\\text{BW}(\\mathbb R^d))\\) defined by \\(\\mathcal{G}(\\nu) = \\mathcal{F}(G_{\\nu})\\). The Wasserstein gradient flow of \\(\\mathcal{G}\\) in \\(\\mathcal{P}_2(\\text{BW}(\\mathbb R^d))\\) is given by the curve \\((\\text{law}(m_t,\\Sigma_t))_{t \\geq 0}\\) for random variables \\(m_t\\) and \\(\\Sigma_t\\) that follow the equations \\[\\begin{align*}\n        \\dot{m}_t &= - \\mathbb E\\nabla  \\delta \\mathcal{F}(G_t) (X_t)\\\\\n        \\dot{\\Sigma}_t &= -\\mathbb E\\nabla^2  \\delta \\mathcal{F}(G_t) (X_t)\\Sigma_t - \\Sigma_t \\mathbb E\\nabla^2  \\delta \\mathcal{F}(G_t) (X_t)\n\\end{align*}\\] where \\(X_t \\sim \\mathcal{N}(m_t,\\Sigma_t)\\)."
  },
  {
    "objectID": "Bures-Wasserstein Gradient Flows.html#gaussian-variational-inference",
    "href": "Bures-Wasserstein Gradient Flows.html#gaussian-variational-inference",
    "title": "Bures-Wasserstein Gradient Flow",
    "section": "Gaussian Variational Inference",
    "text": "Gaussian Variational Inference\nBures-Wasserstein gradient flows can be used to solve variational inference problems when the set of admissible measures is \\(\\text{BW}(\\mathbb R^d)\\) (Lambert et al. 2023).\nThe variational inference is an optimization problem which seeks to find a simple distribution in an admissible set \\(\\Omega\\) which closely approximates a given measure \\(\\pi \\in \\mathcal{P}_2(\\mathbb R^d)\\) in terms of KL divergence. More precisely, variational inference is the problem of finding a measure \\(q_*\\) such that \\[q_* = \\underset{q \\in \\Omega}{\\arg\\min}\\, \\text{KL}(q || \\pi).\\] Gaussian variational inference is the problem \\[q_* = \\underset{q \\in \\text{BW}(\\mathbb R^d)}{\\arg\\min}\\, \\text{KL}(q || \\pi).\\]\nRecent work (cite https://arxiv.org/pdf/2205.15902) takes a gradient flow approach to solving Gaussian variational inference. By computing the Bures-Wasserstein gradient flow of the functional $ = (,,|| ) $, one can discretize the gradient flow and obtain a numerical algorithm to approximate a local minimizer of \\(\\mathcal{F}\\).\nIn order to do so, one must derive the Bures-Wasserstein gradient of \\(\\mathcal{F}\\). This is done via the variational characterization of Bures-Wasserstein gradients. For an absolutely continuous measure \\(\\pi\\) with a density \\(\\exp(-V)\\) (\\(V\\) is called the potential), the first variation of $ = (,,|| ) $ is \\[\\nabla\\delta\\mathcal{F}(q) = \\nabla V + \\nabla \\log q\\] and \\[\\nabla^2\\delta\\mathcal{F}(q) = \\nabla^2 V + \\nabla^2 \\log q\\] where \\(\\log q(x)\\) denotes the logarithm of the density of \\(q\\) at \\(x\\).\nBy the formula for Bures-Wasserstein gradients, we see that \\[\\begin{align*}      \\nabla_{\\text{BW}}\\mathcal{F}(q)(x) &= \\bigg( \\int \\big( \\nabla^2 V + \\nabla^2 \\log q \\big) dq \\bigg) (x-m_q) + \\int \\big( \\nabla V + \\nabla \\log q \\big) dq\\\\\n    &= \\bigg( \\int \\big( \\nabla^2 V + \\nabla^2 \\log q \\big) dq \\bigg) (x-m_q) + \\int \\nabla V dq + \\int \\nabla \\log q dq.\n\\end{align*}\\] Because \\(q = \\mathcal{N}(m,\\Sigma)\\) is Gaussian we know \\(\\log q (x) = - \\frac{1}{2}(x-m)\\Sigma^{-1}(x-m) + c\\) where \\(c\\) is some constant. This implies \\(\\log q\\) symmetric about the mean \\(m\\) of \\(q\\), \\(\\nabla \\log q\\) is antisymmetric about \\(m\\), and hence the integral \\(\\int_{\\mathbb R} \\nabla \\log q dq = 0\\). Thus, \\[\\begin{align*}                 \n\\nabla_{\\text{BW}}\\mathcal{F}(q)(x) &= \\bigg( \\int \\big( \\nabla^2 V + \\nabla^2 \\log q \\big) dq \\bigg) (x-m_q) + \\int \\nabla V dq.\n\\end{align*}\\] Further, since \\(\\log q (x) = (x-m)\\Sigma^{-1}(x-m) + c\\) we know that \\(\\nabla^2 \\log q (x) = -\\Sigma^{-1}\\), so we conclude that \\[\\begin{align*}                 \n\\nabla_{\\text{BW}}\\mathcal{F}(q)(x) &= \\bigg( \\int \\nabla^2 V dq - \\Sigma^{-1} \\bigg) (x-m_q) + \\int \\nabla V dq.\n\\end{align*}\\]\nIn addition, since \\(\\text{KL}(\\,\\cdot\\,|| \\pi)\\) is convex on \\(\\mathcal{P}_2(\\mathbb R^d)\\), its restriction to \\(\\text{BW}(\\mathbb R^d)\\) is also a convex functional because \\(\\text{BW}(\\mathbb R^d)\\) is geodesically convex. This implies that \\(\\text{KL}(q_t|| \\pi)\\) will converge to \\(\\text{KL}(q_*|| \\pi)\\) exponentially for any gradient flow \\((q_t)_{t\\geq 0}\\) of \\(\\text{KL}(\\,\\cdot\\,|| \\pi)\\)."
  },
  {
    "objectID": "GFMetricSpace.html",
    "href": "GFMetricSpace.html",
    "title": "Gradient Flows in Metric Space",
    "section": "",
    "text": "We first briefly reivew gradient flows in \\(\\mathbb{R}^n\\). The motivation comes from the so-called “gradient descent method”: Suppose we would like to find the minimizer of a certain (continuously differentiable) function \\(F:\\mathbb{R}^n\\to \\mathbb{R}\\). A classical way is to start with any point \\(x_0\\), and then go along the direction of negative of gradient of \\(F\\). That is, we are solving\n\\[\\begin{array}{l}\nx^{\\prime}(t)=-\\nabla F(x(t)) \\quad \\text { for } t&gt;0, \\\\\nx(0)=x_0.\n\\end{array}\\]\nA solution to the above initial value problem (IVP) is called a gradient flow of \\(F\\). As the gradient always points at the direction where \\(F\\) increases the most, negative gradient will lead us to a (local) minimizer of \\(F\\). The existence and uniqueness theory of ODE guarantees a satisfactory solution of this gradient flow.\n\n\nNote that along any smooth curve \\(x_t\\) it holds that \\(\\begin{aligned} F(x(s))-F(x(t))=\\int_s^t-\\nabla F(x(r)) \\cdot x^{\\prime}(r) \\mathrm{d} r & \\leq \\int_s^t|\\nabla F(x(r))|\\left|x^{\\prime}(r)\\right| \\mathrm{d} r \\\\ & \\leq \\int_s^t\\left(\\frac{1}{2}\\left|x^{\\prime}(r)\\right|^2+\\frac{1}{2}|\\nabla F(x(r))|^2\\right) \\mathrm{d} r\\end{aligned}\\)\nNote that if \\(x(t)\\) solves the gradient flow IVP, then\n\\[\nF(x(s))-F(x(t))=\\int_s^t\\left(\\frac{1}{2}\\left|x^{\\prime}(r)\\right|^2+\\frac{1}{2}|\\nabla F(x(r))|^2\\right) \\mathrm{d} r, \\quad  \\forall s&lt;t\n\\] which we call Energy Dissipation Enequality (EDE).\nNow if \\(F\\) is \\(\\lambda\\)-convex, the inequality that characterizes the gradient is\n\\[\nF(y) \\geq F(x)+\\frac{\\lambda}{2}|x-y|^2+p \\cdot(y-x) \\quad \\text { for all } y \\in \\mathbb{R}^d .\n\\] We can pick a curve \\(x(t)\\) and a point \\(y\\) and compute\n\\[\n\\frac{d}{d t} \\frac{1}{2}|x(t)-y|^2=(y-x(t)) \\cdot\\left(-x^{\\prime}(t)\\right)\n\\]\nConsequently, imposing\n\\[\n\\frac{d}{d t} \\frac{1}{2}|x(t)-y|^2 \\leq F(y)-F(x(t))-\\frac{\\lambda}{2}|x(t)-y|^2\n\\]\nfor all \\(y\\), will be equivalent to \\(-x^{\\prime}(t) \\in-\\partial F(x(t))\\). This will provide a second characterization (called EVI, Evolution Variational Inequality) of gradient flows in a metric environment."
  },
  {
    "objectID": "GFMetricSpace.html#gradient-flows-in-euclidean-space",
    "href": "GFMetricSpace.html#gradient-flows-in-euclidean-space",
    "title": "Gradient Flows in Metric Space",
    "section": "",
    "text": "We first briefly reivew gradient flows in \\(\\mathbb{R}^n\\). The motivation comes from the so-called “gradient descent method”: Suppose we would like to find the minimizer of a certain (continuously differentiable) function \\(F:\\mathbb{R}^n\\to \\mathbb{R}\\). A classical way is to start with any point \\(x_0\\), and then go along the direction of negative of gradient of \\(F\\). That is, we are solving\n\\[\\begin{array}{l}\nx^{\\prime}(t)=-\\nabla F(x(t)) \\quad \\text { for } t&gt;0, \\\\\nx(0)=x_0.\n\\end{array}\\]\nA solution to the above initial value problem (IVP) is called a gradient flow of \\(F\\). As the gradient always points at the direction where \\(F\\) increases the most, negative gradient will lead us to a (local) minimizer of \\(F\\). The existence and uniqueness theory of ODE guarantees a satisfactory solution of this gradient flow.\n\n\nNote that along any smooth curve \\(x_t\\) it holds that \\(\\begin{aligned} F(x(s))-F(x(t))=\\int_s^t-\\nabla F(x(r)) \\cdot x^{\\prime}(r) \\mathrm{d} r & \\leq \\int_s^t|\\nabla F(x(r))|\\left|x^{\\prime}(r)\\right| \\mathrm{d} r \\\\ & \\leq \\int_s^t\\left(\\frac{1}{2}\\left|x^{\\prime}(r)\\right|^2+\\frac{1}{2}|\\nabla F(x(r))|^2\\right) \\mathrm{d} r\\end{aligned}\\)\nNote that if \\(x(t)\\) solves the gradient flow IVP, then\n\\[\nF(x(s))-F(x(t))=\\int_s^t\\left(\\frac{1}{2}\\left|x^{\\prime}(r)\\right|^2+\\frac{1}{2}|\\nabla F(x(r))|^2\\right) \\mathrm{d} r, \\quad  \\forall s&lt;t\n\\] which we call Energy Dissipation Enequality (EDE).\nNow if \\(F\\) is \\(\\lambda\\)-convex, the inequality that characterizes the gradient is\n\\[\nF(y) \\geq F(x)+\\frac{\\lambda}{2}|x-y|^2+p \\cdot(y-x) \\quad \\text { for all } y \\in \\mathbb{R}^d .\n\\] We can pick a curve \\(x(t)\\) and a point \\(y\\) and compute\n\\[\n\\frac{d}{d t} \\frac{1}{2}|x(t)-y|^2=(y-x(t)) \\cdot\\left(-x^{\\prime}(t)\\right)\n\\]\nConsequently, imposing\n\\[\n\\frac{d}{d t} \\frac{1}{2}|x(t)-y|^2 \\leq F(y)-F(x(t))-\\frac{\\lambda}{2}|x(t)-y|^2\n\\]\nfor all \\(y\\), will be equivalent to \\(-x^{\\prime}(t) \\in-\\partial F(x(t))\\). This will provide a second characterization (called EVI, Evolution Variational Inequality) of gradient flows in a metric environment."
  },
  {
    "objectID": "GFMetricSpace.html#gradient-flows-in-metric-space",
    "href": "GFMetricSpace.html#gradient-flows-in-metric-space",
    "title": "Gradient Flows in Metric Space",
    "section": "Gradient Flows in Metric Space",
    "text": "Gradient Flows in Metric Space\nTo generalize the above IVP, we need to make sense of derivative and gradient in metric space setting.\nThe first notion is the generalization of “derivative” in metric space, so-called metric derivative defined as follows: Given a curve \\(x:[0, T] \\rightarrow X\\) valued in a metric space, \\[\n\\left|x^{\\prime}\\right|(t):=\\lim _{h \\rightarrow 0} \\frac{d(x(t), x(t+h))}{|h|}.\n\\] Note that there is no vector structure here, so we can only make sense of modulus of the velocity of a curve.\nThe second concept is the generalization of convexity. A function \\(F\\) is called geodeiscally convex if it is convex along any geodesic: \\[F(x(t)) \\leq(1-t) F(x(0))+t F(x(1)).\\] Similarly we define geodeisc \\(\\lambda\\)-convex if \\[\nF(x(t)) \\leq(1-t) F(x(0))+t F(x(1))-\\lambda \\frac{t(1-t)}{2} d^2(x(0), x(1)) .\n\\]\nLastly we define the metric version of \\(|\\nabla F|\\) as slope: Let \\(F: X \\rightarrow \\mathbb{R} \\cup\\{+\\infty\\}\\) and \\(x \\in X\\) be such that \\(F(x)&lt;\\infty\\). Then the slope \\(|\\nabla F|(x)\\) of \\(F\\) at \\(x\\) is:\n\\[\n|\\nabla F|(x):=\\varlimsup_{y \\rightarrow x} \\frac{(F(x)-F(y))^{+}}{d(x, y)}=\\max \\left\\{\\varlimsup_{y \\rightarrow x} \\frac{F(x)-F(y)}{d(x, y)}, 0\\right\\} .\n\\]\nNow we are ready to define gradient flows in metric setting. There are two definitions(Ambrosio et al. 2013):\n(Energy Dissipation Equality definition of GF - EDE) Let \\(E: X \\rightarrow \\mathbb{R} \\cup\\{+\\infty\\}\\) and let \\(\\bar{x} \\in X\\) be such that \\(E(\\bar{x})&lt;\\infty\\). We say that \\([0, \\infty) \\ni t \\mapsto x_t \\in X\\) is a Gradient Flow in the EDE sense starting at \\(\\bar{x}\\) provided it is a locally absolutely continuous curve, \\(x_0=\\bar{x}\\) and\n\\[\nE\\left(x_s\\right)+\\frac{1}{2} \\int_t^s\\left|\\dot{x}_r\\right|^2 d r+\\frac{1}{2} \\int_t^s|\\nabla E|^2\\left(x_r\\right) d r=E\\left(x_t\\right), \\quad \\forall 0 \\leq t \\leq s\n\\]\nThe second definition is the EVI version:\n(Evolution Variation Inequality definition of GF - EVI) Let \\(E: X \\rightarrow \\mathbb{R} \\cup\\{+\\infty\\}\\), \\(\\bar{x} \\in \\overline{\\{E&lt;\\infty\\}}\\) and \\(\\lambda \\in \\mathbb{R}\\). We say that \\((0, \\infty) \\ni t \\mapsto x_t \\in X\\) is a Gradient Flow in the EVI sense (with respect to \\(\\lambda\\) ) starting at \\(\\bar{x}\\) provided it is a locally absolutely continuous curve in \\((0, \\infty), x_t \\rightarrow \\bar{x}\\) as \\(t \\rightarrow 0\\) and\n\\[\nE\\left(x_t\\right)+\\frac{1}{2} \\frac{d}{d t} d^2\\left(x_t, y\\right)+\\frac{\\lambda}{2} d^2\\left(x_t, y\\right) \\leq E(y), \\quad \\forall y \\in X, \\text { a.e. } t&gt;0\n\\]\nIt turns out that the EDE definition is weaker than the EVI definition, i.e. any EVI GF is automatically an EDE GF. The EDE definition is easier to get existence, and the EVI definition is used to get uniqueness results."
  },
  {
    "objectID": "WassersteinOnGraphs.html",
    "href": "WassersteinOnGraphs.html",
    "title": "Wasserstein-like Metrics on Graphs",
    "section": "",
    "text": "Motivation\nOn Euclidean space, it is known that the solution to the heat equation can be viewed as a gradient flow. In other words, consider the heat equation \\[ \\begin{cases}\n          \\partial_t u(t, x) = \\Delta u(t, x) \\\\\n          u(0,\\cdot)=u_0(\\cdot) . \\\\  \n       \\end{cases}\n    \\] We construct the energy functional \\(\\mathcal{F}:L^2(\\mathbb{R}^d) \\rightarrow \\mathbb{R}\\), given by \\[ \\mathcal{F}(f)=\\int_{\\mathbb{R}^d}f(x)\\ln(f(x))dx . \\] Consider the metric space \\((P_2(\\mathbb{R}^d), W_2)\\), where \\(W_2\\) denotes the 2-Wasserstein metric, and \\[ P_2(\\mathbb{R}^d) = \\left \\{ \\mu \\in P(\\mathbb{R}^d) : \\int_{\\mathbb{R}^d} |x|^2 d \\mu(x) &lt; \\infty \\right \\} . \\] This is a geodesic space, so the operator \\(\\nabla_{W_2}\\) is well-defined. Based on the seminal work of Jordan, Kinderlehrer and Otto in (Jordan 1998), we know that the solution to the heat equation, \\(u(t, x)\\), satisfies \\[\n    \\partial_t u(t, x) = -\\nabla_{W_2}\\mathcal{F}(u(t,x)) .\n\\tag{1}\\] This result has been extended to non-Euclidean base spaces. In other words, in many instances, we replace \\(\\mathbb{R}^d\\) with a more abstract space (e.g. a Riemannian manifold). Then, we develop an analogue to \\(W_2\\) so that Equation 1 still holds. In this article, we will replace \\(\\mathbb{R}^d\\) with a finite directed graph \\(G\\), and then construct an analogue to the 2-Wasserstein metric so that heat flow is the gradient flow of the entropy.\n\n\nSetting: Graphs and Markov Chains\nConsider a complete finite weighted graph \\(G\\) with nodes \\(X = \\{x_1, \\ldots, x_n \\}\\). Let \\(K = \\{ k_{ij} \\}\\) contain the edge weight from \\(x_i\\) to \\(x_j\\). By a slight abuse of notation, we will define \\(K(x_i, y_j) = k_{ij}\\). We may view our graph as a continuous-time Markov chain with states \\(\\{ x_1, \\ldots, x_n \\}\\). Then, we let \\(Q = K - I\\) be the transition matrix associated with our Markov chain. The associated continuous time semigroup is given by \\[ H(t) = e^{tQ} . \\] We will assume that \\[ k_{ij} \\geq 0 \\; \\forall i, j, \\; \\sum \\limits_{j = 1}^n k_{ij} = 1 \\; \\forall i . \\] We will further assume that \\(K\\) is irreducible, and hence has a unique steady state \\(\\pi\\), where \\(\\pi = \\pi K\\). By elementary Markov chain theory, we know that \\(\\pi\\) is strictly positive. Consider the set \\[ P(X) = \\left \\{ \\rho: X \\rightarrow \\mathbb{R} : \\rho(x) \\geq 0 \\; \\forall x \\in X : \\sum \\limits_{x \\in X} \\rho(x)\\pi(x) = 1 \\right \\} . \\] Intuitively, \\(P(X)\\) can be thought of as the set of all probability density functions on \\(X\\); for each \\(\\rho \\in P(X)\\), there is a corresponding measure \\(\\mu\\) on \\(X\\), where \\[ \\mu(A) = \\sum \\limits_{x \\in A} \\rho(x) \\pi(x) \\; \\forall A \\subseteq X . \\]\n\n\nA New Metric on \\(P(X)\\)\nLet \\(\\theta: \\mathbb{R}_+ \\times \\mathbb{R}_+ \\rightarrow \\mathbb{R}_+\\) equal the logarithmic mean, i.e. \\[ \\theta(s, t) = \\begin{cases}\n    s & s = t \\\\\n    \\frac{s - t}{\\ln(s) - \\ln(t)} & \\text{otherwise}.\n\\end{cases}\\] Then, we define \\(\\rho(x, y) = \\theta(\\rho(x), \\rho(y))\\). For \\(\\rho_0, \\rho_1 \\in P(S)\\), we define \\[ W(\\rho_0, \\rho_1)^2 = \\inf \\limits_{\\rho, \\psi} \\left \\{ \\frac{1}{2} \\int_0^1 \\sum \\limits_{x, y \\in X} \\left ( \\psi_t(x) - \\psi_t(y)\\right )^2 K(x, y) \\rho_t(x, y) \\pi(x) dt \\right \\} , \\] where the infimum runs over all piecewise \\(C^1\\) curves \\(\\rho:[0, 1] \\rightarrow P(X)\\) and all measurable functions \\(\\psi:[0, 1] \\rightarrow \\mathbb{R}^X\\) satisfying for a.e. \\(t \\in [0, 1]\\), \\[ \\begin{cases}\n    \\frac{d}{dt} \\rho_t(x) + \\sum \\limits_{y \\in X}  ( \\psi_t(x) - \\psi_t(y) ) K(x, y) \\rho_t(x, y) = 0 & \\forall x \\in X \\\\\n    \\rho(0) = \\rho_0, \\rho(1) = \\rho_1 .\n\\end{cases} \\] Readers who are familiar with the Benamou-Brenier formula will note the similarity between this definition and that formula. We have the following:\n\nTheorem 1 The following assertions hold:\n\n\\(W\\) defines a pseudo-metric on \\(P(X)\\).\n\\(W(\\rho_0, \\rho_1) &lt; \\infty\\) for all \\(\\rho_0, \\rho_1 \\in P(X)\\).\n\\(W\\) metrises the topology of weak convergence.\n\n\n\nTheorem 2 Let \\(H(\\rho) = \\sum \\limits_{x \\in X} \\pi(x) \\rho(x) \\ln(\\rho(x))\\) be the entropy functional. For \\(\\rho \\in P(X)\\) and \\(t \\geq 0\\), set \\(\\rho_t = e^{t(K - I)}\\). Then the gradient flow equation \\[ D_t \\rho = - \\nabla H(\\rho_t) \\] holds for all \\(t &gt; 0\\).\n\nProofs for these theorems can be found in (Maas 2011).\n\n\nThe Two Point Space\nConsider the case \\(X = (a, b)\\), \\[ K = \\begin{bmatrix}\n    1 - p & p \\\\\n    q & 1 - q\n\\end{bmatrix}. \\] If we define \\(\\rho^{\\beta} = \\frac{1}{2} \\left ( (1 - \\beta)\\delta_a + (1 + \\beta) \\delta_b \\right )\\), then \\[ P(X) = \\left \\{ \\rho^{\\beta} : \\beta \\in [-1, 1] \\right \\} . \\] In this special case, our metric \\(W\\) reduces to \\[ W(\\rho^{\\alpha}, \\rho^{\\beta}) =  \\int_{\\alpha}^{\\beta} \\frac{1}{\\sqrt{2\\theta(q(1 + r), p(1 - r))}} dr , \\] where \\(\\alpha \\leq \\beta\\). Notice that if we define \\[ \\varphi(\\beta) = \\int_{0}^{\\beta}  \\frac{1}{\\sqrt{2 \\theta(q(1 + r), p(1 - r))}}dr , \\] then for any \\(\\alpha, \\beta \\in [-1, 1]\\), \\[ W(\\rho^{\\alpha}, \\rho^{\\beta}) = |\\varphi(\\alpha) - \\varphi(\\beta)| . \\] As a result, the function \\(J: P(X) \\rightarrow [-1, 1]\\), \\[ J(\\rho^{\\beta}) = \\varphi(\\beta) \\] defines an isometry from \\((P(X), W)\\) to \\(([-1, 1], |\\cdot|)\\). We can exploit this isometry when identifying constant-speed geodesics in \\((P(X), W)\\).\n\nTheorem 3 Choose \\(\\alpha, \\beta \\in [-1, 1]\\). There exists a unique constant speed geodesic \\(\\{ p^{\\gamma(t)} \\}_{t \\in [0, 1]}\\), where \\(\\gamma \\in C^1([0, 1], \\mathbb{R})\\) and \\[ \\begin{cases}\n    \\gamma'(t) = \\omega \\sqrt{ 2 \\theta(q(1 + \\gamma(t)), p(1 - \\gamma(t))) } \\\\\n    \\gamma(0) = \\alpha \\\\\n    \\gamma(1) = \\beta,\n\\end{cases} \\] where \\(\\omega = sgn(\\beta - \\alpha) W(\\rho^{\\alpha}, \\rho^{\\beta})\\).\n\n\nProof. Since \\(J\\) is an isometry, existence and uniqueness of \\(\\gamma(t)\\) immediately follows. To show \\(\\rho^{\\gamma(t)}\\) is a constant speed geodesic, let \\(\\gamma\\) be the curve described above. Choose \\(0 \\leq s &lt; t \\leq 1\\), and note \\[\\begin{align*}\n    W \\left (\\rho^{\\gamma(t)}, \\rho^{\\gamma(s)} \\right )\n    & = |\\varphi(\\gamma(t)) - \\varphi(\\gamma(s))| \\\\\n    & = \\left | \\int_s^t \\varphi'(\\gamma(r)) \\cdot \\gamma'(r) dr \\right | \\\\\n    & = \\left | \\int_s^t  \\frac{1}{\\sqrt{2 \\theta(q(1 + \\gamma(t)), p(1 - \\gamma(t)))}} \\cdot \\omega \\sqrt{ 2 \\theta(p(1 - \\gamma(t)), q(1 + \\gamma(t))) } dr \\right | \\\\\n    & = |t - s| W\\left(\\rho^{\\alpha}, \\rho^{\\beta}\\right) .\n\\end{align*}\\]\n\n\n\n\n\n\nReferences\n\nJordan, et al. 1998. “The Variational Formulation of the Fokker–Planck Equation.”\n\n\nMaas, Jan. 2011. “Gradient Flows of the Entropy for Finite Markov Chains.”"
  },
  {
    "objectID": "Dynamic_OT.html",
    "href": "Dynamic_OT.html",
    "title": "Dynamic Optimal Transport",
    "section": "",
    "text": "The dynamic formulation of optimal transport is one of the four main formulations of the optimal transport problem (the other three being the Monge Problem, the Kantorovich Problem, and the Kantorovich Dual Problem). Rather than minimizing over transport maps or transport plans between measures \\(\\mu\\) and \\(\\nu\\), the dynamic formulation of optimal transport minimizes over curves which connect \\(\\mu\\) and \\(\\nu\\).\nMinimizing over curves (as opposed to maps or plans) has at least two major advantages. First, it allows for continuous interpolation between measures in the Wasserstein space. This is desirable in several applications.\nSecond, minimization over curves generalizes to many settings where transport maps or plans may not be well defined or may be difficult to define. This allows for the construction of optimal transport-based metrics in nonclassical settings, such as Optimal Transport on Graphs or Unbalanced Optimal Transport.\nThe original formulation of the dynamic optimal transport problem is due to (Benamou and Brenier 2000). However, a somewhat different formulation is presented in this article following (Ambrosio et al. 2021) which is based on integrals defined on the path space of the underlying metric space. We will compare these two approaches later in this article."
  },
  {
    "objectID": "Dynamic_OT.html#preliminaries",
    "href": "Dynamic_OT.html#preliminaries",
    "title": "Dynamic Optimal Transport",
    "section": "Preliminaries",
    "text": "Preliminaries\nLet \\((X,d)\\) be a metric space. Recall that a curve \\(\\gamma: [a,b] \\to X\\) is said to be absolutely continuous if there exists \\(g \\in L^1(a,b)\\) such that \\[\nd(\\gamma(r),\\gamma(s)) ~\\leq~ \\int_r^s g(t) \\, dt\n\\] for all \\(a \\leq r \\leq s \\leq b\\). The space of absolutely continuous curves from \\([a,b]\\) to \\(X\\) is denoted \\(\\text{AC}([a,b],X)\\).\nThe metric dertivative of \\(\\gamma \\in \\text{AC}([a,b],X)\\) is defined as \\[\n|\\gamma'|(t) ~:=~ \\lim_{h \\to 0} \\frac{d(\\gamma(t),\\gamma(t+h))}{|h|} .\n\\] The metric derivative formalizes the notion of “speed” of the curve \\(\\gamma\\), and is defined for a.e.-\\(t\\). The metric derivative is the minimal \\(g\\) that can be chosen in the definition of absolute continuity above.\nThe length of \\(\\gamma\\) is then defined as \\[\n\\ell(\\gamma) ~:=~ \\int_a^b |\\gamma'|(t) \\, dt .\n\\]\nNote that by reparameterizing the time variable, any curve in \\(\\text{AC}([a,b],X)\\) can be transformed into a curve in \\(\\text{AC}([0,1],X)\\) with constant speed \\(|\\gamma'| \\equiv \\ell(\\gamma) = \\text{constant}\\).\nThe above definitions imply that for any curve \\(\\gamma \\in \\text{AC}([a,b],X)\\), it holds that \\(\\ell(\\gamma) \\geq d(\\gamma(a),\\gamma(b))\\), i.e., that the length of \\(\\gamma\\) is greater than the distance between its endpoints. Any curve which achieves equality \\(\\ell(\\gamma) = d(\\gamma(a),\\gamma(b))\\) is termed a geodesic. The space of constant-speed geodesics on the interval \\([0,1]\\) is denoted \\(\\text{Geo}(X)\\).\nA metric space \\(X\\) is said to be geodesic if for all \\(x,y \\in X\\) there exists \\(\\gamma \\in \\text{Geo}(X)\\) such that \\(\\gamma(0) = x\\) and \\(\\gamma(1) = y\\).\nSee Analysis in Metric Spaces for a review of these ideas.\nGeneralizing the notion of length, the (\\(p\\)-) action of a curve \\(\\gamma \\in \\text{AC}([0,1],X)\\) is defined as \\[\nA_p(\\gamma) ~:=~ \\int_0^1 |\\gamma'|^p (t) \\, dt .\n\\] Note that this quantity is possibly infinite. This definition can be extended to all of \\(C([0,1],X)\\) by setting \\(A_p(\\gamma) = + \\infty\\) if \\(\\gamma \\in C([0,1],X) \\backslash AC([0,1],X)\\).\nGeodesics can then be characterized by a variational principle involving the action.\n\nLemma.\nFor \\(\\gamma \\in \\text{AC}([0,1],X)\\) and \\(1 \\leq p &lt; \\infty\\), \\(\\gamma \\in \\text{Geo}(X)\\) if and only if \\(A_p(\\gamma) = d^p(\\gamma(0),\\gamma(1))\\).\n\n\nProof.\nThe forward direction is immediate, since \\(\\gamma \\in \\text{Geo}(X)\\) means that \\(|\\gamma'| \\equiv \\ell(\\gamma) = d(\\gamma(0),\\gamma(1))\\) by definition. The reverse direction follows from Jensen’s inequality, since \\[\nA_p(\\gamma) ~:=~ \\int_0^1 |\\gamma'|^p(t) \\, dt ~\\geq~ \\left( \\int_0^1 |\\gamma'|(t) \\, dt \\right)^p ~=:~ \\ell^p(\\gamma) ~\\geq~ d^p(\\gamma(0),\\gamma(1)) ,\n\\] with equality being achieved if and only if \\(\\gamma \\in \\text{Geo}(X)\\). \\(\\square\\)\nThe space \\(C([0,1],X)\\) is termed the path space over \\(X\\). The dynamic formulation of optimal transport is posed in terms of probability measures on this path space, i.e., in terms of \\(\\eta \\in P(C([0,1],X))\\).\nThe evaluation map \\(e_t: C([0,1],X) \\to X\\) is defined by \\(e_t(\\gamma) := \\gamma(t)\\). The evaluation map acts on probability measures on the path space by pushforward \\((e_t)_\\# : P(C([0,1],X)) \\to P(X)\\). Thus \\((e_t)_\\# \\eta\\) is itself a path in \\(P(X)\\)."
  },
  {
    "objectID": "Dynamic_OT.html#the-dynamic-optimal-transport-problem",
    "href": "Dynamic_OT.html#the-dynamic-optimal-transport-problem",
    "title": "Dynamic Optimal Transport",
    "section": "The Dynamic Optimal Transport Problem",
    "text": "The Dynamic Optimal Transport Problem\nThe dynamic optimal transport problem is stated as follows. Given probability measures \\(\\mu, \\nu \\in P(X)\\), solve \\[\n\\min_\\eta ~ \\int_{C([0,1],X)} A_p(\\gamma) \\, d \\eta(\\gamma) \\qquad \\text{s.t.} \\qquad \\eta \\in P(C([0,1],X)), ~~(e_0)_\\# \\eta = \\mu , ~~ (e_1)_\\# \\eta = \\nu .\n\\] An admissible \\(\\eta\\) is termed a dynamic transport plan and an optimal \\(\\eta\\) is termed an optimal dynamic tranport plan. This terminology is justified by the fact that \\(\\eta\\) is an admissible dynamic transport plan if and only if \\((e_0,e_1)_\\# \\eta\\) is an admissible tranport plan. A dynamic transport plan \\(\\eta\\), however, encodes not only information about which particles in \\(\\mu\\) are transported to which particles in \\(\\nu\\), but about which trajectories these particles take during the transport process.\n\nTheorem.\nIf \\((X,d)\\) is a Polish and geodesic metric space, then the minimum attained for the dynamic optimal transport problem is equal to the minimum attained for the Kantorovich problem. Furthermore, \\(\\eta\\) is optimal if and only if \\((e_0,e_1)_\\# \\eta\\) is optimal for the Kantorovich problem and \\(\\eta\\) is supported on \\(\\text{Geo}(X)\\).\n\n\nProof.\nIf \\(\\eta\\) is an admissible dynamic transport plan, then \\[\n\\begin{align}\n\\int_{C([0,1],X)} A_p(\\gamma) \\, d\\eta(\\gamma) ~&\\geq~ \\int_{C([0,1],X)} d^p(\\gamma(0),\\gamma(1)) \\, d\\eta(\\gamma) \\\\\n~&=~ \\int_{X \\times X} d^p(x,y) \\, d(e_0,e_1)_\\# \\eta(x,y) \\\\\n~&\\geq~ \\min_\\pi \\mathbb{K}_p(\\pi) .\n\\end{align}\n\\] To prove the converse, start from an optimal transport plan \\(\\pi\\) and for each \\((x,y) \\in X \\times X\\), choose \\(\\gamma_{x,y} \\in \\text{Geo}(X)\\) such that \\(\\gamma_{x,y}(0) = x\\) and \\(\\gamma_{x,y}(1) = y\\). Define the map \\(\\Gamma: X \\times X \\to \\text{Geo}(X)\\) by \\(\\Gamma(x,y) = \\gamma_{x,y}\\) and the measure \\(\\eta := \\Gamma_\\# \\pi \\in P(C([0,1],X))\\). By construction, \\(\\eta\\) is supported in \\(\\text{Geo}(X)\\). Thus \\[\n\\begin{align}\n\\min_\\pi \\mathbb{K}_p(\\gamma) ~&=~ \\int_{X \\times X} d^p(x,y) \\, d\\pi(x,y) \\\\\n~&=~ \\int_{C([0,1],X)} d^p(\\gamma(0),\\gamma(1)) \\, d\\eta(\\gamma) \\\\\n~&=~ \\int_{C([0,1],X)} A_p(\\gamma) \\, d\\eta(\\gamma)\n\\end{align}\n\\] by the previous lemma, and equality is achieved.\nLastly, observe that \\(\\eta\\) is optimal if and only if equality is achieved above, which happens if and only if \\(\\gamma\\) is supported in \\(\\text{Geo}(X)\\) and \\((e_0,e_1)_\\# \\eta\\) is optimal for the Kantorovich problem. \\(\\square\\)"
  },
  {
    "objectID": "Dynamic_OT.html#comparison-with-original-formulation",
    "href": "Dynamic_OT.html#comparison-with-original-formulation",
    "title": "Dynamic Optimal Transport",
    "section": "Comparison With Original Formulation",
    "text": "Comparison With Original Formulation\nThe original formulation of dynamic optimal transport due to (Benamou and Brenier 2000) is posed as follows. Given probability measures \\(\\mu, \\nu \\in P(X)\\), solve \\[\n\\begin{align}\n\\min_{\\rho,v} ~ \\int_0^1 \\int_X \\| v(t,x) \\|^p \\, d \\rho(t,x) \\, dt \\qquad \\text{s.t.} \\qquad &\\partial_t \\rho(t,x) = - \\nabla \\cdot (\\rho(t,x) v(t,x)), \\\\\n~~ &\\rho(0) = \\mu, ~~ \\rho(1) = \\nu .\n\\end{align}\n\\] Here, \\(\\rho\\) is a time-varying probability measure on \\(X\\) and \\(v\\) is a time-varying vector field which acts to transport \\(\\rho\\). Individual particles are considered to be transported according to \\(x'(t) = v(x,t)\\), and thus the continuity equation \\(\\partial_t \\rho = - \\nabla \\cdot (\\rho v)\\) describes how the density \\(\\rho\\) evolves under the action of \\(v\\). (Note the abuse of notation here: the symbol \\(\\rho\\) is used both for the measure and for its density function.)\nIn order to interpret the statement of this problem appropriately, \\(X\\) needs to be a subset of Euclidean space (or some Riemannian manifold) and the continuity equation must be understood in some appropriate weak sense.\nSee The Continuity Equation and Benamou Brenier Formula and Geodesics and Generalized Geodesics for more on these ideas.\nIf \\(\\mu\\) has a density function, then particles start from unique locations, and we can write \\(\\phi(t,x)\\) to denote the location (at time \\(t\\)) of the particle which started from location \\(x\\) at time \\(0\\). It then holds that \\[\n\\rho(t) ~=~ (\\phi(t,\\cdot))_\\# \\rho(0) ~=~ (\\phi(t,\\cdot))_\\# \\mu .\n\\] Substituting this into the objective function and using properties of the pushforward, the objective can be rewritten \\[\n~=~ \\int_0^1 \\int_X \\| v(t, \\phi(t,x)) \\|^p \\, d \\mu(x) \\, dt .\n\\] Recognizing the quantity \\(\\| v(t,\\phi(t,x)) \\| = \\| \\tfrac{d}{dt}\\phi(t,x) \\|\\) as the metric derivative of the trajectory \\(\\phi(\\cdot,x)\\) and interchanging the order of integration, we obtain \\[\n~=~ \\int_X \\int_0^1 |\\phi'(\\cdot,x)|^p(t) \\, dt \\, d\\mu(x) ~=:~ \\int_X A_p(\\phi(\\cdot,x)) \\, d\\mu(x) .\n\\] Lastly, defining \\(\\eta := \\phi_\\# \\mu\\) and letting \\(\\gamma\\) range over all possible paths from \\([0,1]\\) into \\(X\\) gives \\[\n~=~ \\int_{C([0,1],X)} A_p(\\gamma) \\, d\\eta(\\gamma) ,\n\\] thus recovering the formulation presented earlier.\nTherefore, when \\(X\\) is a subset of Euclidean space (or a Riemannian manifold) and when \\(\\mu\\) has a density with respect to Lebesgue measure, the two formulations presented are equivalent. When \\(\\mu\\) does not have a density, the original formulation can be further weakened to maintain equivalence. However, when \\(X\\) is a general metric space, only the earlier formulation in terms of integrals on the path space is valid."
  }
]